{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "video_yolu = \"MOT20-01-raw.webm\"\n",
        "cap = cv2.VideoCapture(video_yolu)\n",
        "\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "genislik = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "yukseklik = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "\n",
        "cikis_yolu = \"output_MOT20-01.mp4\"\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(cikis_yolu, fourcc, fps, (genislik, yukseklik))\n",
        "\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")  \n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    \n",
        "    sonuclar = model(frame)\n",
        "\n",
        "    \n",
        "    for sonuc in sonuclar:\n",
        "        for kutu in sonuc.boxes:\n",
        "           \n",
        "            x1, y1, x2, y2 = map(int, kutu.xyxy[0].tolist())\n",
        "            guven = kutu.conf[0]  \n",
        "            etiket = model.names[int(kutu.cls[0])]  \n",
        "\n",
        "           \n",
        "            if etiket == \"person\":\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                cv2.putText(frame, f\"{etiket} {guven:.2f}\", (x1, y1 - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"saved video: {cikis_yolu}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n0: 384x640 19 persons, 1 umbrella, 199.8ms\nSpeed: 3.3ms preprocess, 199.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 189.8ms\nSpeed: 15.6ms preprocess, 189.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 155.7ms\nSpeed: 5.9ms preprocess, 155.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 312.5ms\nSpeed: 0.0ms preprocess, 312.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 horses, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 horse, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 154.6ms\nSpeed: 0.0ms preprocess, 154.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 handbag, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 170.4ms\nSpeed: 15.6ms preprocess, 170.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 handbags, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 139.3ms\nSpeed: 0.0ms preprocess, 139.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 handbags, 148.3ms\nSpeed: 0.0ms preprocess, 148.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 1 handbag, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 139.3ms\nSpeed: 0.0ms preprocess, 139.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 136.5ms\nSpeed: 18.7ms preprocess, 136.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 154.5ms\nSpeed: 0.0ms preprocess, 154.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 183.7ms\nSpeed: 0.0ms preprocess, 183.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 191.8ms\nSpeed: 4.0ms preprocess, 191.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 217.3ms\nSpeed: 0.0ms preprocess, 217.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 187.5ms\nSpeed: 15.6ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 1 clock, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 294.3ms\nSpeed: 0.0ms preprocess, 294.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 254.0ms\nSpeed: 15.6ms preprocess, 254.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 180.9ms\nSpeed: 6.0ms preprocess, 180.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 161.5ms\nSpeed: 0.0ms preprocess, 161.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 150.4ms\nSpeed: 0.0ms preprocess, 150.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 238.5ms\nSpeed: 0.7ms preprocess, 238.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 355.2ms\nSpeed: 9.8ms preprocess, 355.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 149.0ms\nSpeed: 5.0ms preprocess, 149.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 109.4ms\nSpeed: 0.0ms preprocess, 109.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 134.8ms\nSpeed: 15.6ms preprocess, 134.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 handbags, 1 tv, 131.6ms\nSpeed: 4.0ms preprocess, 131.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 4 handbags, 2 tvs, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 tv, 125.0ms\nSpeed: 0.0ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 214.6ms\nSpeed: 4.2ms preprocess, 214.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 150.5ms\nSpeed: 15.6ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 150.9ms\nSpeed: 14.4ms preprocess, 150.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 161.8ms\nSpeed: 10.7ms preprocess, 161.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 148.6ms\nSpeed: 0.0ms preprocess, 148.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 136.5ms\nSpeed: 13.6ms preprocess, 136.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 142.2ms\nSpeed: 5.0ms preprocess, 142.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 157.9ms\nSpeed: 14.7ms preprocess, 157.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 149.9ms\nSpeed: 0.6ms preprocess, 149.9ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 2 tvs, 150.0ms\nSpeed: 0.0ms preprocess, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 3 tvs, 167.0ms\nSpeed: 0.0ms preprocess, 167.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 133.5ms\nSpeed: 16.7ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 148.5ms\nSpeed: 0.0ms preprocess, 148.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 1 handbag, 1 tv, 137.7ms\nSpeed: 14.6ms preprocess, 137.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 1 tv, 150.0ms\nSpeed: 0.0ms preprocess, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 handbag, 1 tv, 149.8ms\nSpeed: 0.0ms preprocess, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 2 tvs, 150.1ms\nSpeed: 17.7ms preprocess, 150.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 199.3ms\nSpeed: 15.9ms preprocess, 199.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 201.5ms\nSpeed: 15.0ms preprocess, 201.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 199.9ms\nSpeed: 2.2ms preprocess, 199.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 1 clock, 208.3ms\nSpeed: 0.0ms preprocess, 208.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 2 tvs, 187.5ms\nSpeed: 15.6ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 190.5ms\nSpeed: 0.0ms preprocess, 190.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 232.3ms\nSpeed: 9.2ms preprocess, 232.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 2 tvs, 209.0ms\nSpeed: 5.1ms preprocess, 209.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 142.8ms\nSpeed: 0.0ms preprocess, 142.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 1 tv, 1 clock, 140.5ms\nSpeed: 15.6ms preprocess, 140.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 2 tvs, 127.7ms\nSpeed: 4.5ms preprocess, 127.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 109.4ms\nSpeed: 15.6ms preprocess, 109.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 143.3ms\nSpeed: 0.0ms preprocess, 143.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 158.4ms\nSpeed: 0.0ms preprocess, 158.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 192.0ms\nSpeed: 8.7ms preprocess, 192.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 163.9ms\nSpeed: 15.6ms preprocess, 163.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 191.3ms\nSpeed: 0.0ms preprocess, 191.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 216.0ms\nSpeed: 14.4ms preprocess, 216.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 backpack, 1 umbrella, 1 handbag, 216.5ms\nSpeed: 0.0ms preprocess, 216.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 196.9ms\nSpeed: 0.0ms preprocess, 196.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 182.7ms\nSpeed: 5.9ms preprocess, 182.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 2 handbags, 171.4ms\nSpeed: 6.0ms preprocess, 171.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 271.9ms\nSpeed: 6.0ms preprocess, 271.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 1 tv, 296.9ms\nSpeed: 0.0ms preprocess, 296.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 296.9ms\nSpeed: 15.6ms preprocess, 296.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 205.5ms\nSpeed: 0.0ms preprocess, 205.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 174.5ms\nSpeed: 15.6ms preprocess, 174.5ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 1 clock, 201.6ms\nSpeed: 0.0ms preprocess, 201.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 169.0ms\nSpeed: 0.0ms preprocess, 169.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 199.8ms\nSpeed: 0.0ms preprocess, 199.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 horse, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 247.9ms\nSpeed: 0.0ms preprocess, 247.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 218.7ms\nSpeed: 4.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 208.3ms\nSpeed: 0.0ms preprocess, 208.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 270.6ms\nSpeed: 10.0ms preprocess, 270.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 232.4ms\nSpeed: 0.0ms preprocess, 232.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 167.6ms\nSpeed: 0.0ms preprocess, 167.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 167.5ms\nSpeed: 0.0ms preprocess, 167.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 158.2ms\nSpeed: 4.0ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 164.4ms\nSpeed: 0.0ms preprocess, 164.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 167.7ms\nSpeed: 0.0ms preprocess, 167.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 150.9ms\nSpeed: 15.4ms preprocess, 150.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 152.9ms\nSpeed: 14.3ms preprocess, 152.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 150.1ms\nSpeed: 0.9ms preprocess, 150.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 147.5ms\nSpeed: 16.7ms preprocess, 147.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 152.0ms\nSpeed: 14.9ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 167.0ms\nSpeed: 0.0ms preprocess, 167.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 142.5ms\nSpeed: 5.0ms preprocess, 142.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 167.7ms\nSpeed: 0.0ms preprocess, 167.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 151.1ms\nSpeed: 17.1ms preprocess, 151.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 150.0ms\nSpeed: 0.0ms preprocess, 150.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 154.0ms\nSpeed: 14.3ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 clock, 183.7ms\nSpeed: 0.0ms preprocess, 183.7ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 150.0ms\nSpeed: 0.0ms preprocess, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 144.1ms\nSpeed: 0.0ms preprocess, 144.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.5ms\nSpeed: 4.5ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 218.3ms\nSpeed: 15.6ms preprocess, 218.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 192.5ms\nSpeed: 4.8ms preprocess, 192.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 208.5ms\nSpeed: 2.5ms preprocess, 208.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 178.0ms\nSpeed: 15.6ms preprocess, 178.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 148.6ms\nSpeed: 5.8ms preprocess, 148.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 166.8ms\nSpeed: 4.5ms preprocess, 166.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 167.3ms\nSpeed: 0.0ms preprocess, 167.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 133.0ms\nSpeed: 16.8ms preprocess, 133.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 134.5ms\nSpeed: 5.0ms preprocess, 134.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 horse, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 2 handbags, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 186.4ms\nSpeed: 3.4ms preprocess, 186.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 141.4ms\nSpeed: 5.0ms preprocess, 141.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 154.0ms\nSpeed: 15.6ms preprocess, 154.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 168.2ms\nSpeed: 15.3ms preprocess, 168.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 161.3ms\nSpeed: 13.9ms preprocess, 161.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 2 tvs, 151.9ms\nSpeed: 4.4ms preprocess, 151.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 164.1ms\nSpeed: 17.1ms preprocess, 164.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 167.4ms\nSpeed: 11.5ms preprocess, 167.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 162.1ms\nSpeed: 0.0ms preprocess, 162.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 168.0ms\nSpeed: 0.0ms preprocess, 168.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 392.4ms\nSpeed: 5.0ms preprocess, 392.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 223.2ms\nSpeed: 0.0ms preprocess, 223.2ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 1 clock, 316.4ms\nSpeed: 47.6ms preprocess, 316.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 195.1ms\nSpeed: 5.6ms preprocess, 195.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 275.6ms\nSpeed: 0.0ms preprocess, 275.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 203.3ms\nSpeed: 5.3ms preprocess, 203.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 204.7ms\nSpeed: 15.6ms preprocess, 204.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 234.5ms\nSpeed: 0.0ms preprocess, 234.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 232.2ms\nSpeed: 0.0ms preprocess, 232.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 1 clock, 197.2ms\nSpeed: 5.0ms preprocess, 197.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 219.8ms\nSpeed: 0.0ms preprocess, 219.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 241.3ms\nSpeed: 0.0ms preprocess, 241.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 227.3ms\nSpeed: 5.0ms preprocess, 227.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 235.9ms\nSpeed: 13.4ms preprocess, 235.9ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 268.3ms\nSpeed: 0.0ms preprocess, 268.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 382.7ms\nSpeed: 5.0ms preprocess, 382.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 220.6ms\nSpeed: 5.4ms preprocess, 220.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 150.3ms\nSpeed: 4.0ms preprocess, 150.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 231.3ms\nSpeed: 15.6ms preprocess, 231.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 212.3ms\nSpeed: 6.0ms preprocess, 212.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 350.2ms\nSpeed: 0.0ms preprocess, 350.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 200.2ms\nSpeed: 10.9ms preprocess, 200.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 201.5ms\nSpeed: 15.6ms preprocess, 201.5ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 397.2ms\nSpeed: 9.3ms preprocess, 397.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 205.2ms\nSpeed: 15.6ms preprocess, 205.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 246.4ms\nSpeed: 17.6ms preprocess, 246.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 205.0ms\nSpeed: 5.6ms preprocess, 205.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 tv, 216.2ms\nSpeed: 5.5ms preprocess, 216.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 227.0ms\nSpeed: 12.5ms preprocess, 227.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 194.6ms\nSpeed: 5.5ms preprocess, 194.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 236.0ms\nSpeed: 4.0ms preprocess, 236.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 191.2ms\nSpeed: 10.5ms preprocess, 191.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 171.0ms\nSpeed: 5.9ms preprocess, 171.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 169.5ms\nSpeed: 5.0ms preprocess, 169.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 167.2ms\nSpeed: 5.0ms preprocess, 167.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 163.5ms\nSpeed: 4.2ms preprocess, 163.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 204.5ms\nSpeed: 5.6ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 203.8ms\nSpeed: 15.6ms preprocess, 203.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 208.2ms\nSpeed: 19.9ms preprocess, 208.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 207.0ms\nSpeed: 7.0ms preprocess, 207.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 231.3ms\nSpeed: 5.0ms preprocess, 231.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 148.5ms\nSpeed: 0.0ms preprocess, 148.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 210.6ms\nSpeed: 0.0ms preprocess, 210.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 143.9ms\nSpeed: 15.6ms preprocess, 143.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 164.5ms\nSpeed: 4.6ms preprocess, 164.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 150.6ms\nSpeed: 5.0ms preprocess, 150.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 168.6ms\nSpeed: 5.0ms preprocess, 168.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 134.8ms\nSpeed: 5.0ms preprocess, 134.8ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 160.5ms\nSpeed: 0.0ms preprocess, 160.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 motorcycle, 2 tvs, 129.7ms\nSpeed: 6.0ms preprocess, 129.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 155.6ms\nSpeed: 0.0ms preprocess, 155.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 239.1ms\nSpeed: 5.0ms preprocess, 239.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 190.5ms\nSpeed: 0.0ms preprocess, 190.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 194.7ms\nSpeed: 2.4ms preprocess, 194.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 203.3ms\nSpeed: 5.0ms preprocess, 203.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 2 tvs, 231.6ms\nSpeed: 0.0ms preprocess, 231.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 230.0ms\nSpeed: 5.5ms preprocess, 230.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 219.4ms\nSpeed: 5.0ms preprocess, 219.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 188.3ms\nSpeed: 4.8ms preprocess, 188.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 3 tvs, 209.5ms\nSpeed: 0.0ms preprocess, 209.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 279.0ms\nSpeed: 10.9ms preprocess, 279.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 221.2ms\nSpeed: 15.6ms preprocess, 221.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 220.3ms\nSpeed: 15.6ms preprocess, 220.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 3 tvs, 201.0ms\nSpeed: 5.0ms preprocess, 201.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 2 tvs, 208.8ms\nSpeed: 0.0ms preprocess, 208.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 3 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 188.5ms\nSpeed: 15.6ms preprocess, 188.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 204.6ms\nSpeed: 0.0ms preprocess, 204.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 3 tvs, 224.4ms\nSpeed: 15.6ms preprocess, 224.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 3 tvs, 229.5ms\nSpeed: 15.6ms preprocess, 229.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 backpack, 1 handbag, 1 tv, 220.5ms\nSpeed: 0.0ms preprocess, 220.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 handbag, 1 tv, 217.2ms\nSpeed: 0.0ms preprocess, 217.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 backpacks, 1 handbag, 2 tvs, 195.4ms\nSpeed: 15.6ms preprocess, 195.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 2 tvs, 216.8ms\nSpeed: 4.0ms preprocess, 216.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 umbrella, 2 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 handbag, 2 tvs, 209.2ms\nSpeed: 0.0ms preprocess, 209.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 1 handbag, 2 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 188.1ms\nSpeed: 0.0ms preprocess, 188.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 tv, 265.6ms\nSpeed: 0.0ms preprocess, 265.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 backpack, 1 umbrella, 2 tvs, 157.9ms\nSpeed: 15.6ms preprocess, 157.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 tv, 155.9ms\nSpeed: 0.0ms preprocess, 155.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 173.7ms\nSpeed: 0.0ms preprocess, 173.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 228.6ms\nSpeed: 0.0ms preprocess, 228.6ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 212.6ms\nSpeed: 4.0ms preprocess, 212.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 204.5ms\nSpeed: 16.8ms preprocess, 204.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 214.2ms\nSpeed: 0.0ms preprocess, 214.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 184.9ms\nSpeed: 6.2ms preprocess, 184.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 2 tvs, 228.5ms\nSpeed: 0.0ms preprocess, 228.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 195.4ms\nSpeed: 5.0ms preprocess, 195.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 142.0ms\nSpeed: 5.0ms preprocess, 142.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 1 tv, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 tv, 150.5ms\nSpeed: 15.6ms preprocess, 150.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 145.9ms\nSpeed: 0.0ms preprocess, 145.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 246.3ms\nSpeed: 0.0ms preprocess, 246.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 218.6ms\nSpeed: 0.0ms preprocess, 218.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 backpack, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 235.9ms\nSpeed: 0.0ms preprocess, 235.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 145.9ms\nSpeed: 0.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 147.2ms\nSpeed: 0.0ms preprocess, 147.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 157.9ms\nSpeed: 0.0ms preprocess, 157.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 201.0ms\nSpeed: 0.0ms preprocess, 201.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 204.7ms\nSpeed: 0.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 189.3ms\nSpeed: 0.0ms preprocess, 189.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 224.1ms\nSpeed: 15.6ms preprocess, 224.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 26 persons, 1 umbrella, 169.6ms\nSpeed: 0.0ms preprocess, 169.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 157.9ms\nSpeed: 15.6ms preprocess, 157.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 173.8ms\nSpeed: 14.3ms preprocess, 173.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 172.5ms\nSpeed: 5.0ms preprocess, 172.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 238.8ms\nSpeed: 5.0ms preprocess, 238.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 216.8ms\nSpeed: 0.0ms preprocess, 216.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 220.1ms\nSpeed: 0.0ms preprocess, 220.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 236.0ms\nSpeed: 0.0ms preprocess, 236.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 234.4ms\nSpeed: 15.6ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 220.3ms\nSpeed: 15.6ms preprocess, 220.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 206.5ms\nSpeed: 0.0ms preprocess, 206.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 240.2ms\nSpeed: 4.0ms preprocess, 240.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 199.8ms\nSpeed: 15.6ms preprocess, 199.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 205.5ms\nSpeed: 5.0ms preprocess, 205.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 203.9ms\nSpeed: 15.6ms preprocess, 203.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 204.6ms\nSpeed: 5.5ms preprocess, 204.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 213.0ms\nSpeed: 0.0ms preprocess, 213.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 210.3ms\nSpeed: 0.0ms preprocess, 210.3ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 228.8ms\nSpeed: 8.2ms preprocess, 228.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 246.8ms\nSpeed: 0.0ms preprocess, 246.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 244.5ms\nSpeed: 5.0ms preprocess, 244.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 194.3ms\nSpeed: 4.5ms preprocess, 194.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 221.4ms\nSpeed: 0.0ms preprocess, 221.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 220.6ms\nSpeed: 0.0ms preprocess, 220.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 233.0ms\nSpeed: 0.0ms preprocess, 233.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 208.3ms\nSpeed: 15.6ms preprocess, 208.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 215.4ms\nSpeed: 0.0ms preprocess, 215.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 169.2ms\nSpeed: 5.0ms preprocess, 169.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 158.7ms\nSpeed: 5.0ms preprocess, 158.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 175.4ms\nSpeed: 5.0ms preprocess, 175.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 164.2ms\nSpeed: 5.2ms preprocess, 164.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 221.2ms\nSpeed: 0.0ms preprocess, 221.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 204.8ms\nSpeed: 15.6ms preprocess, 204.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 191.6ms\nSpeed: 0.0ms preprocess, 191.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 211.2ms\nSpeed: 0.0ms preprocess, 211.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 168.3ms\nSpeed: 5.4ms preprocess, 168.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 152.5ms\nSpeed: 5.0ms preprocess, 152.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 136.4ms\nSpeed: 15.6ms preprocess, 136.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 174.0ms\nSpeed: 0.0ms preprocess, 174.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 163.8ms\nSpeed: 6.3ms preprocess, 163.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 196.1ms\nSpeed: 0.0ms preprocess, 196.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 217.2ms\nSpeed: 5.3ms preprocess, 217.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 218.1ms\nSpeed: 15.6ms preprocess, 218.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 229.0ms\nSpeed: 5.0ms preprocess, 229.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 210.6ms\nSpeed: 15.6ms preprocess, 210.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 174.4ms\nSpeed: 0.0ms preprocess, 174.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 162.9ms\nSpeed: 0.0ms preprocess, 162.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 168.3ms\nSpeed: 6.1ms preprocess, 168.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 180.6ms\nSpeed: 5.0ms preprocess, 180.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 216.6ms\nSpeed: 9.0ms preprocess, 216.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 223.8ms\nSpeed: 6.0ms preprocess, 223.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 229.1ms\nSpeed: 15.6ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 220.4ms\nSpeed: 7.0ms preprocess, 220.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 211.5ms\nSpeed: 6.3ms preprocess, 211.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 194.2ms\nSpeed: 5.0ms preprocess, 194.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 242.0ms\nSpeed: 0.0ms preprocess, 242.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 250.2ms\nSpeed: 5.0ms preprocess, 250.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 150.9ms\nSpeed: 0.0ms preprocess, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 177.4ms\nSpeed: 0.0ms preprocess, 177.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 168.1ms\nSpeed: 6.7ms preprocess, 168.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 208.5ms\nSpeed: 4.5ms preprocess, 208.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 204.0ms\nSpeed: 0.0ms preprocess, 204.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 204.8ms\nSpeed: 0.0ms preprocess, 204.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 296.9ms\nSpeed: 0.0ms preprocess, 296.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 234.8ms\nSpeed: 0.0ms preprocess, 234.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 234.1ms\nSpeed: 15.6ms preprocess, 234.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 235.2ms\nSpeed: 0.0ms preprocess, 235.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 204.7ms\nSpeed: 0.0ms preprocess, 204.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 214.6ms\nSpeed: 0.0ms preprocess, 214.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 219.1ms\nSpeed: 0.0ms preprocess, 219.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 227.2ms\nSpeed: 0.0ms preprocess, 227.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 216.4ms\nSpeed: 15.6ms preprocess, 216.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 210.1ms\nSpeed: 0.0ms preprocess, 210.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 212.4ms\nSpeed: 5.0ms preprocess, 212.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 246.3ms\nSpeed: 15.6ms preprocess, 246.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 233.8ms\nSpeed: 0.0ms preprocess, 233.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\nsaved video: output_MOT20-01.mp4\n"
        }
      ],
      "execution_count": 1,
      "metadata": {},
      "id": "bc2c4e75-8c8b-452f-8db0-61587fd358a0"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ground_truth(file_path=\"gt.txt\"):\n",
        "    ground_truth = {}\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\",\")\n",
        "            frame_id = int(parts[0])\n",
        "            x1 = int(parts[2])\n",
        "            y1 = int(parts[3])\n",
        "            width = int(parts[4])\n",
        "            height = int(parts[5])\n",
        "            x2 = x1 + width\n",
        "            y2 = y1 + height\n",
        "            ground_truth[frame_id] = (x1, y1, x2, y2)\n",
        "    return ground_truth\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {},
      "id": "fbafc51f-1c9a-4756-8ed1-1fe36a70d42a"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def iou(box1, box2):\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    union = area_box1 + area_box2 - intersection\n",
        "    return intersection / union if union > 0 else 0\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {},
      "id": "0ee0b9ad-0507-41b4-b9d8-0f5da42672b5"
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "\n",
        "ground_truth = load_ground_truth(\"gt.txt\")\n",
        "\n",
        "video_path = \"MOT20-01-raw.webm\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "iou_scores = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_id = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "\n",
        "    if frame_id not in ground_truth:\n",
        "        continue\n",
        "\n",
        "    gt_box = ground_truth[frame_id]\n",
        "    results = model(frame)\n",
        "\n",
        "    max_iou = 0\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            label = model.names[int(box.cls[0])]\n",
        "\n",
        "            if label == \"person\":\n",
        "                detected_box = (x1, y1, x2, y2)\n",
        "                max_iou = max(max_iou, iou(gt_box, detected_box))\n",
        "\n",
        "    iou_scores.append((frame_id, max_iou))\n",
        "\n",
        "cap.release()\n",
        "\n",
        "\n",
        "for frame_id, score in iou_scores:\n",
        "    print(f\"Frame {frame_id}: IoU = {score:.2f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n0: 384x640 19 persons, 1 umbrella, 229.9ms\nSpeed: 15.6ms preprocess, 229.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 233.9ms\nSpeed: 0.0ms preprocess, 233.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 180.3ms\nSpeed: 5.0ms preprocess, 180.3ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 221.8ms\nSpeed: 0.0ms preprocess, 221.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 horses, 1 umbrella, 188.3ms\nSpeed: 0.0ms preprocess, 188.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 horse, 1 umbrella, 250.6ms\nSpeed: 0.0ms preprocess, 250.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 157.8ms\nSpeed: 0.0ms preprocess, 157.8ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 137.7ms\nSpeed: 5.0ms preprocess, 137.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 157.3ms\nSpeed: 18.8ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 208.8ms\nSpeed: 0.0ms preprocess, 208.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 handbag, 230.3ms\nSpeed: 7.5ms preprocess, 230.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 205.2ms\nSpeed: 5.0ms preprocess, 205.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 208.4ms\nSpeed: 0.0ms preprocess, 208.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 214.0ms\nSpeed: 0.0ms preprocess, 214.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 220.3ms\nSpeed: 15.6ms preprocess, 220.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 handbags, 174.5ms\nSpeed: 0.0ms preprocess, 174.5ms inference, 37.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 277.7ms\nSpeed: 39.1ms preprocess, 277.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 179.3ms\nSpeed: 0.0ms preprocess, 179.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 176.1ms\nSpeed: 4.0ms preprocess, 176.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 167.1ms\nSpeed: 3.6ms preprocess, 167.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 142.3ms\nSpeed: 15.6ms preprocess, 142.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 147.9ms\nSpeed: 0.0ms preprocess, 147.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 161.7ms\nSpeed: 10.2ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 150.2ms\nSpeed: 15.6ms preprocess, 150.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 handbag, 150.0ms\nSpeed: 0.0ms preprocess, 150.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 145.5ms\nSpeed: 0.0ms preprocess, 145.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 handbags, 146.8ms\nSpeed: 15.6ms preprocess, 146.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 135.6ms\nSpeed: 5.3ms preprocess, 135.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 142.8ms\nSpeed: 0.0ms preprocess, 142.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 146.7ms\nSpeed: 0.0ms preprocess, 146.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 144.5ms\nSpeed: 0.0ms preprocess, 144.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 141.5ms\nSpeed: 15.6ms preprocess, 141.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 133.4ms\nSpeed: 6.0ms preprocess, 133.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 153.5ms\nSpeed: 0.0ms preprocess, 153.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 124.7ms\nSpeed: 15.2ms preprocess, 124.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 155.0ms\nSpeed: 0.0ms preprocess, 155.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 134.4ms\nSpeed: 15.6ms preprocess, 134.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 153.4ms\nSpeed: 15.6ms preprocess, 153.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 140.6ms\nSpeed: 3.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 140.4ms\nSpeed: 0.0ms preprocess, 140.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 125.0ms\nSpeed: 15.6ms preprocess, 125.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 162.4ms\nSpeed: 5.0ms preprocess, 162.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 178.1ms\nSpeed: 0.0ms preprocess, 178.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 174.6ms\nSpeed: 0.0ms preprocess, 174.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 165.9ms\nSpeed: 1.9ms preprocess, 165.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 174.0ms\nSpeed: 0.0ms preprocess, 174.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 159.0ms\nSpeed: 0.0ms preprocess, 159.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.6ms\nSpeed: 15.6ms preprocess, 171.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 235.7ms\nSpeed: 0.0ms preprocess, 235.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 218.1ms\nSpeed: 5.0ms preprocess, 218.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 224.9ms\nSpeed: 0.0ms preprocess, 224.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 192.8ms\nSpeed: 0.0ms preprocess, 192.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 214.3ms\nSpeed: 0.0ms preprocess, 214.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 223.2ms\nSpeed: 3.0ms preprocess, 223.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 220.7ms\nSpeed: 4.6ms preprocess, 220.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 213.4ms\nSpeed: 0.0ms preprocess, 213.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 211.6ms\nSpeed: 15.6ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 288.8ms\nSpeed: 4.0ms preprocess, 288.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 253.3ms\nSpeed: 7.0ms preprocess, 253.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 428.5ms\nSpeed: 4.7ms preprocess, 428.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 231.8ms\nSpeed: 15.6ms preprocess, 231.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 1 clock, 220.3ms\nSpeed: 0.0ms preprocess, 220.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 254.0ms\nSpeed: 0.0ms preprocess, 254.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 222.4ms\nSpeed: 4.0ms preprocess, 222.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 220.4ms\nSpeed: 14.5ms preprocess, 220.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 320.8ms\nSpeed: 3.5ms preprocess, 320.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 213.8ms\nSpeed: 15.6ms preprocess, 213.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 197.0ms\nSpeed: 6.9ms preprocess, 197.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 166.0ms\nSpeed: 6.1ms preprocess, 166.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 190.4ms\nSpeed: 15.6ms preprocess, 190.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 175.0ms\nSpeed: 5.0ms preprocess, 175.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 187.4ms\nSpeed: 0.0ms preprocess, 187.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 201.0ms\nSpeed: 5.6ms preprocess, 201.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 150.3ms\nSpeed: 5.0ms preprocess, 150.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 192.6ms\nSpeed: 0.0ms preprocess, 192.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 188.5ms\nSpeed: 7.0ms preprocess, 188.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 handbags, 1 tv, 184.7ms\nSpeed: 5.0ms preprocess, 184.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 4 handbags, 2 tvs, 170.1ms\nSpeed: 14.4ms preprocess, 170.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 tv, 185.3ms\nSpeed: 5.0ms preprocess, 185.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 255.2ms\nSpeed: 5.0ms preprocess, 255.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 253.1ms\nSpeed: 4.0ms preprocess, 253.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 281.2ms\nSpeed: 4.0ms preprocess, 281.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 226.3ms\nSpeed: 5.0ms preprocess, 226.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 260.6ms\nSpeed: 5.1ms preprocess, 260.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 275.4ms\nSpeed: 0.0ms preprocess, 275.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 241.4ms\nSpeed: 6.0ms preprocess, 241.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 245.3ms\nSpeed: 4.0ms preprocess, 245.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 228.2ms\nSpeed: 7.0ms preprocess, 228.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 2 tvs, 234.2ms\nSpeed: 7.0ms preprocess, 234.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 3 tvs, 239.1ms\nSpeed: 5.0ms preprocess, 239.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 249.4ms\nSpeed: 6.7ms preprocess, 249.4ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 241.9ms\nSpeed: 4.3ms preprocess, 241.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 1 handbag, 1 tv, 240.4ms\nSpeed: 5.0ms preprocess, 240.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 1 tv, 247.1ms\nSpeed: 6.0ms preprocess, 247.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 handbag, 1 tv, 236.8ms\nSpeed: 5.7ms preprocess, 236.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 2 tvs, 254.8ms\nSpeed: 0.0ms preprocess, 254.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 250.7ms\nSpeed: 6.0ms preprocess, 250.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 256.0ms\nSpeed: 5.0ms preprocess, 256.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 259.0ms\nSpeed: 5.0ms preprocess, 259.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 1 clock, 247.7ms\nSpeed: 4.9ms preprocess, 247.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 363.8ms\nSpeed: 3.9ms preprocess, 363.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 2 tvs, 267.3ms\nSpeed: 5.0ms preprocess, 267.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 245.3ms\nSpeed: 0.0ms preprocess, 245.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 259.2ms\nSpeed: 15.6ms preprocess, 259.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 269.1ms\nSpeed: 5.0ms preprocess, 269.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 283.0ms\nSpeed: 6.7ms preprocess, 283.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 2 tvs, 276.7ms\nSpeed: 6.0ms preprocess, 276.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 302.2ms\nSpeed: 5.0ms preprocess, 302.2ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 269.4ms\nSpeed: 9.2ms preprocess, 269.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 1 tv, 1 clock, 252.9ms\nSpeed: 7.3ms preprocess, 252.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 2 tvs, 256.3ms\nSpeed: 5.0ms preprocess, 256.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 251.8ms\nSpeed: 11.8ms preprocess, 251.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 248.7ms\nSpeed: 5.0ms preprocess, 248.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 288.7ms\nSpeed: 6.0ms preprocess, 288.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 265.8ms\nSpeed: 5.0ms preprocess, 265.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 266.8ms\nSpeed: 6.0ms preprocess, 266.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 260.5ms\nSpeed: 5.0ms preprocess, 260.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 254.9ms\nSpeed: 5.0ms preprocess, 254.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 267.4ms\nSpeed: 5.6ms preprocess, 267.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 backpack, 1 umbrella, 1 handbag, 281.2ms\nSpeed: 5.0ms preprocess, 281.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 295.2ms\nSpeed: 3.0ms preprocess, 295.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 303.1ms\nSpeed: 0.0ms preprocess, 303.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 2 handbags, 245.3ms\nSpeed: 5.0ms preprocess, 245.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 247.6ms\nSpeed: 5.0ms preprocess, 247.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 1 tv, 257.5ms\nSpeed: 9.0ms preprocess, 257.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 222.2ms\nSpeed: 4.7ms preprocess, 222.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 247.3ms\nSpeed: 0.0ms preprocess, 247.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 258.4ms\nSpeed: 6.0ms preprocess, 258.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 256.6ms\nSpeed: 4.9ms preprocess, 256.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 1 clock, 249.1ms\nSpeed: 1.0ms preprocess, 249.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 236.7ms\nSpeed: 2.3ms preprocess, 236.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 219.6ms\nSpeed: 9.7ms preprocess, 219.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 horse, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 264.9ms\nSpeed: 0.0ms preprocess, 264.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 229.9ms\nSpeed: 4.0ms preprocess, 229.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 347.9ms\nSpeed: 5.0ms preprocess, 347.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 210.9ms\nSpeed: 18.1ms preprocess, 210.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 182.5ms\nSpeed: 6.7ms preprocess, 182.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 208.8ms\nSpeed: 6.7ms preprocess, 208.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 244.3ms\nSpeed: 4.6ms preprocess, 244.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 192.2ms\nSpeed: 7.0ms preprocess, 192.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 201.0ms\nSpeed: 5.8ms preprocess, 201.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 202.0ms\nSpeed: 16.8ms preprocess, 202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 189.4ms\nSpeed: 0.0ms preprocess, 189.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 185.9ms\nSpeed: 4.7ms preprocess, 185.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 317.8ms\nSpeed: 15.7ms preprocess, 317.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 240.2ms\nSpeed: 16.8ms preprocess, 240.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 231.8ms\nSpeed: 6.1ms preprocess, 231.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 229.3ms\nSpeed: 5.0ms preprocess, 229.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 190.2ms\nSpeed: 5.0ms preprocess, 190.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 210.7ms\nSpeed: 10.0ms preprocess, 210.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 240.9ms\nSpeed: 5.0ms preprocess, 240.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 246.8ms\nSpeed: 6.0ms preprocess, 246.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 228.8ms\nSpeed: 5.0ms preprocess, 228.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 240.0ms\nSpeed: 5.0ms preprocess, 240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 221.4ms\nSpeed: 4.0ms preprocess, 221.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 220.7ms\nSpeed: 2.0ms preprocess, 220.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 224.8ms\nSpeed: 6.0ms preprocess, 224.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 202.5ms\nSpeed: 5.0ms preprocess, 202.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 clock, 246.4ms\nSpeed: 4.4ms preprocess, 246.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 208.3ms\nSpeed: 5.4ms preprocess, 208.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 227.5ms\nSpeed: 13.0ms preprocess, 227.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 222.9ms\nSpeed: 6.1ms preprocess, 222.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 216.4ms\nSpeed: 5.0ms preprocess, 216.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 199.8ms\nSpeed: 13.7ms preprocess, 199.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 216.8ms\nSpeed: 7.3ms preprocess, 216.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 225.7ms\nSpeed: 14.6ms preprocess, 225.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 195.8ms\nSpeed: 4.4ms preprocess, 195.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 216.3ms\nSpeed: 7.2ms preprocess, 216.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 210.3ms\nSpeed: 5.0ms preprocess, 210.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 205.2ms\nSpeed: 1.1ms preprocess, 205.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 222.6ms\nSpeed: 7.0ms preprocess, 222.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 horse, 1 umbrella, 216.9ms\nSpeed: 0.0ms preprocess, 216.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 2 handbags, 241.9ms\nSpeed: 1.3ms preprocess, 241.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 195.6ms\nSpeed: 15.2ms preprocess, 195.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.5ms\nSpeed: 2.5ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 222.1ms\nSpeed: 0.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 239.9ms\nSpeed: 5.2ms preprocess, 239.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 215.4ms\nSpeed: 5.0ms preprocess, 215.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 2 tvs, 252.6ms\nSpeed: 5.0ms preprocess, 252.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 250.0ms\nSpeed: 0.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 236.3ms\nSpeed: 0.0ms preprocess, 236.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 1 clock, 234.4ms\nSpeed: 15.6ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 169.8ms\nSpeed: 15.6ms preprocess, 169.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 168.4ms\nSpeed: 4.0ms preprocess, 168.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 1 clock, 138.6ms\nSpeed: 5.2ms preprocess, 138.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 138.4ms\nSpeed: 5.0ms preprocess, 138.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 167.2ms\nSpeed: 0.0ms preprocess, 167.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 211.1ms\nSpeed: 6.0ms preprocess, 211.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 234.0ms\nSpeed: 15.6ms preprocess, 234.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 224.9ms\nSpeed: 5.3ms preprocess, 224.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 216.9ms\nSpeed: 5.0ms preprocess, 216.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 194.1ms\nSpeed: 5.0ms preprocess, 194.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 265.6ms\nSpeed: 0.0ms preprocess, 265.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 161.6ms\nSpeed: 15.6ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 164.2ms\nSpeed: 0.0ms preprocess, 164.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 202.1ms\nSpeed: 7.4ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 166.4ms\nSpeed: 0.0ms preprocess, 166.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 178.7ms\nSpeed: 15.6ms preprocess, 178.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 204.9ms\nSpeed: 0.0ms preprocess, 204.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 tv, 167.3ms\nSpeed: 5.4ms preprocess, 167.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 159.1ms\nSpeed: 3.1ms preprocess, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 173.7ms\nSpeed: 15.6ms preprocess, 173.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 184.1ms\nSpeed: 5.6ms preprocess, 184.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 171.4ms\nSpeed: 5.0ms preprocess, 171.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 194.3ms\nSpeed: 0.0ms preprocess, 194.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 224.1ms\nSpeed: 15.6ms preprocess, 224.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 208.5ms\nSpeed: 5.0ms preprocess, 208.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 250.0ms\nSpeed: 0.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 155.9ms\nSpeed: 0.0ms preprocess, 155.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 163.9ms\nSpeed: 0.0ms preprocess, 163.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 196.8ms\nSpeed: 0.0ms preprocess, 196.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 225.8ms\nSpeed: 0.0ms preprocess, 225.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 216.7ms\nSpeed: 0.0ms preprocess, 216.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 189.0ms\nSpeed: 6.0ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 240.2ms\nSpeed: 0.0ms preprocess, 240.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 motorcycle, 2 tvs, 232.2ms\nSpeed: 6.2ms preprocess, 232.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 197.1ms\nSpeed: 6.0ms preprocess, 197.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 196.5ms\nSpeed: 15.6ms preprocess, 196.5ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 207.4ms\nSpeed: 4.0ms preprocess, 207.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 218.9ms\nSpeed: 15.6ms preprocess, 218.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 2 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 236.1ms\nSpeed: 15.6ms preprocess, 236.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 207.8ms\nSpeed: 5.0ms preprocess, 207.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 197.9ms\nSpeed: 15.6ms preprocess, 197.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 3 tvs, 251.7ms\nSpeed: 15.6ms preprocess, 251.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 270.4ms\nSpeed: 6.3ms preprocess, 270.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 239.9ms\nSpeed: 5.0ms preprocess, 239.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 250.0ms\nSpeed: 0.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 3 tvs, 167.2ms\nSpeed: 15.6ms preprocess, 167.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 188.2ms\nSpeed: 4.4ms preprocess, 188.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 2 tvs, 228.2ms\nSpeed: 0.0ms preprocess, 228.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 3 tvs, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 223.5ms\nSpeed: 15.6ms preprocess, 223.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 209.3ms\nSpeed: 0.0ms preprocess, 209.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 3 tvs, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 3 tvs, 164.4ms\nSpeed: 0.0ms preprocess, 164.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 backpack, 1 handbag, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 handbag, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 backpacks, 1 handbag, 2 tvs, 167.6ms\nSpeed: 0.0ms preprocess, 167.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 2 tvs, 250.0ms\nSpeed: 0.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 umbrella, 2 tvs, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 handbag, 2 tvs, 228.1ms\nSpeed: 0.0ms preprocess, 228.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 1 handbag, 2 tvs, 201.4ms\nSpeed: 6.4ms preprocess, 201.4ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 251.4ms\nSpeed: 6.5ms preprocess, 251.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 tv, 187.9ms\nSpeed: 6.0ms preprocess, 187.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 backpack, 1 umbrella, 2 tvs, 171.0ms\nSpeed: 10.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 tv, 190.6ms\nSpeed: 5.2ms preprocess, 190.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 2 tvs, 154.5ms\nSpeed: 6.0ms preprocess, 154.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 218.1ms\nSpeed: 0.0ms preprocess, 218.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 217.4ms\nSpeed: 5.0ms preprocess, 217.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 227.7ms\nSpeed: 4.0ms preprocess, 227.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 225.9ms\nSpeed: 11.4ms preprocess, 225.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 224.0ms\nSpeed: 0.0ms preprocess, 224.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 191.9ms\nSpeed: 15.6ms preprocess, 191.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 2 tvs, 250.0ms\nSpeed: 5.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 1 tv, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 tv, 281.2ms\nSpeed: 0.0ms preprocess, 281.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 164.7ms\nSpeed: 0.0ms preprocess, 164.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 210.1ms\nSpeed: 0.0ms preprocess, 210.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 250.0ms\nSpeed: 46.9ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 235.0ms\nSpeed: 0.0ms preprocess, 235.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 backpack, 1 umbrella, 218.4ms\nSpeed: 15.6ms preprocess, 218.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 193.0ms\nSpeed: 0.0ms preprocess, 193.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 262.2ms\nSpeed: 0.0ms preprocess, 262.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 255.3ms\nSpeed: 0.0ms preprocess, 255.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 265.6ms\nSpeed: 0.0ms preprocess, 265.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 230.4ms\nSpeed: 15.6ms preprocess, 230.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 26 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 222.6ms\nSpeed: 0.0ms preprocess, 222.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 206.7ms\nSpeed: 15.6ms preprocess, 206.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 198.4ms\nSpeed: 0.0ms preprocess, 198.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 203.1ms\nSpeed: 15.6ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 265.6ms\nSpeed: 0.0ms preprocess, 265.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 250.6ms\nSpeed: 0.0ms preprocess, 250.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 224.1ms\nSpeed: 15.6ms preprocess, 224.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 199.7ms\nSpeed: 1.0ms preprocess, 199.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 230.6ms\nSpeed: 15.6ms preprocess, 230.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 247.8ms\nSpeed: 15.6ms preprocess, 247.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 222.7ms\nSpeed: 17.7ms preprocess, 222.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 225.7ms\nSpeed: 0.0ms preprocess, 225.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 233.8ms\nSpeed: 15.6ms preprocess, 233.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 210.1ms\nSpeed: 5.0ms preprocess, 210.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 252.8ms\nSpeed: 0.0ms preprocess, 252.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 233.5ms\nSpeed: 0.0ms preprocess, 233.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 176.4ms\nSpeed: 5.0ms preprocess, 176.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 193.6ms\nSpeed: 16.6ms preprocess, 193.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 179.7ms\nSpeed: 6.0ms preprocess, 179.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 185.3ms\nSpeed: 5.0ms preprocess, 185.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 162.5ms\nSpeed: 15.6ms preprocess, 162.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 236.2ms\nSpeed: 0.0ms preprocess, 236.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 226.1ms\nSpeed: 0.0ms preprocess, 226.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 251.8ms\nSpeed: 0.0ms preprocess, 251.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 234.8ms\nSpeed: 0.0ms preprocess, 234.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 163.4ms\nSpeed: 0.0ms preprocess, 163.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 265.5ms\nSpeed: 0.0ms preprocess, 265.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 239.7ms\nSpeed: 1.0ms preprocess, 239.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 777.1ms\nSpeed: 41.8ms preprocess, 777.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 184.1ms\nSpeed: 0.0ms preprocess, 184.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 177.2ms\nSpeed: 5.0ms preprocess, 177.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 200.3ms\nSpeed: 15.8ms preprocess, 200.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 279.4ms\nSpeed: 0.0ms preprocess, 279.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 258.4ms\nSpeed: 7.4ms preprocess, 258.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 151.9ms\nSpeed: 5.0ms preprocess, 151.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 186.4ms\nSpeed: 6.1ms preprocess, 186.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 9.8ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 196.2ms\nSpeed: 6.4ms preprocess, 196.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 160.3ms\nSpeed: 0.0ms preprocess, 160.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 154.6ms\nSpeed: 5.2ms preprocess, 154.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 159.5ms\nSpeed: 6.5ms preprocess, 159.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 132.1ms\nSpeed: 5.0ms preprocess, 132.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 134.0ms\nSpeed: 6.8ms preprocess, 134.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 145.0ms\nSpeed: 6.4ms preprocess, 145.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 161.5ms\nSpeed: 5.2ms preprocess, 161.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 171.8ms\nSpeed: 6.8ms preprocess, 171.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 186.4ms\nSpeed: 19.7ms preprocess, 186.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 180.0ms\nSpeed: 6.0ms preprocess, 180.0ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 181.3ms\nSpeed: 5.0ms preprocess, 181.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 166.9ms\nSpeed: 7.0ms preprocess, 166.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 191.0ms\nSpeed: 10.3ms preprocess, 191.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 290.1ms\nSpeed: 0.0ms preprocess, 290.1ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 197.4ms\nSpeed: 6.0ms preprocess, 197.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 185.9ms\nSpeed: 6.9ms preprocess, 185.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.8ms\nSpeed: 7.1ms preprocess, 187.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 186.3ms\nSpeed: 6.0ms preprocess, 186.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 205.7ms\nSpeed: 5.0ms preprocess, 205.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 192.8ms\nSpeed: 8.3ms preprocess, 192.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 192.0ms\nSpeed: 5.5ms preprocess, 192.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 193.7ms\nSpeed: 17.9ms preprocess, 193.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 181.1ms\nSpeed: 6.0ms preprocess, 181.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 236.3ms\nSpeed: 0.0ms preprocess, 236.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 226.9ms\nSpeed: 3.2ms preprocess, 226.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 198.3ms\nSpeed: 7.3ms preprocess, 198.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 198.1ms\nSpeed: 10.5ms preprocess, 198.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 889.3ms\nSpeed: 8.9ms preprocess, 889.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 260.0ms\nSpeed: 6.0ms preprocess, 260.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 271.8ms\nSpeed: 5.0ms preprocess, 271.8ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 289.2ms\nSpeed: 16.6ms preprocess, 289.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 249.9ms\nSpeed: 15.0ms preprocess, 249.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 264.5ms\nSpeed: 5.0ms preprocess, 264.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 245.0ms\nSpeed: 6.0ms preprocess, 245.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 243.8ms\nSpeed: 6.0ms preprocess, 243.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 272.2ms\nSpeed: 6.0ms preprocess, 272.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 243.7ms\nSpeed: 5.0ms preprocess, 243.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 176.7ms\nSpeed: 5.5ms preprocess, 176.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 182.8ms\nSpeed: 5.3ms preprocess, 182.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 182.3ms\nSpeed: 15.3ms preprocess, 182.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 157.5ms\nSpeed: 4.7ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 165.3ms\nSpeed: 17.8ms preprocess, 165.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 151.8ms\nSpeed: 5.2ms preprocess, 151.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\nFrame 1: IoU = 0.02\nFrame 2: IoU = 0.02\nFrame 3: IoU = 0.02\nFrame 4: IoU = 0.02\nFrame 5: IoU = 0.02\nFrame 6: IoU = 0.02\nFrame 7: IoU = 0.02\nFrame 8: IoU = 0.02\nFrame 9: IoU = 0.02\nFrame 10: IoU = 0.02\nFrame 11: IoU = 0.02\nFrame 12: IoU = 0.02\nFrame 13: IoU = 0.02\nFrame 14: IoU = 0.02\nFrame 15: IoU = 0.02\nFrame 16: IoU = 0.02\nFrame 17: IoU = 0.02\nFrame 18: IoU = 0.02\nFrame 19: IoU = 0.02\nFrame 20: IoU = 0.02\nFrame 21: IoU = 0.02\nFrame 22: IoU = 0.02\nFrame 23: IoU = 0.02\nFrame 24: IoU = 0.02\nFrame 25: IoU = 0.02\nFrame 26: IoU = 0.02\nFrame 27: IoU = 0.02\nFrame 28: IoU = 0.02\nFrame 29: IoU = 0.02\nFrame 30: IoU = 0.02\nFrame 31: IoU = 0.02\nFrame 32: IoU = 0.02\nFrame 33: IoU = 0.02\nFrame 34: IoU = 0.02\nFrame 35: IoU = 0.02\nFrame 36: IoU = 0.02\nFrame 37: IoU = 0.02\nFrame 38: IoU = 0.02\nFrame 39: IoU = 0.02\nFrame 40: IoU = 0.02\nFrame 41: IoU = 0.02\nFrame 42: IoU = 0.02\nFrame 43: IoU = 0.02\nFrame 44: IoU = 0.02\nFrame 45: IoU = 0.02\nFrame 46: IoU = 0.02\nFrame 47: IoU = 0.02\nFrame 48: IoU = 0.02\nFrame 49: IoU = 0.02\nFrame 50: IoU = 0.02\nFrame 51: IoU = 0.02\nFrame 52: IoU = 0.02\nFrame 53: IoU = 0.02\nFrame 54: IoU = 0.02\nFrame 55: IoU = 0.02\nFrame 56: IoU = 0.02\nFrame 57: IoU = 0.02\nFrame 58: IoU = 0.02\nFrame 59: IoU = 0.02\nFrame 60: IoU = 0.02\nFrame 61: IoU = 0.02\nFrame 62: IoU = 0.02\nFrame 63: IoU = 0.02\nFrame 64: IoU = 0.02\nFrame 65: IoU = 0.02\nFrame 66: IoU = 0.02\nFrame 67: IoU = 0.02\nFrame 68: IoU = 0.02\nFrame 69: IoU = 0.02\nFrame 70: IoU = 0.02\nFrame 71: IoU = 0.02\nFrame 72: IoU = 0.02\nFrame 73: IoU = 0.02\nFrame 74: IoU = 0.02\nFrame 75: IoU = 0.02\nFrame 76: IoU = 0.02\nFrame 77: IoU = 0.02\nFrame 78: IoU = 0.02\nFrame 79: IoU = 0.02\nFrame 80: IoU = 0.02\nFrame 81: IoU = 0.02\nFrame 82: IoU = 0.02\nFrame 83: IoU = 0.02\nFrame 84: IoU = 0.02\nFrame 85: IoU = 0.02\nFrame 86: IoU = 0.02\nFrame 87: IoU = 0.02\nFrame 88: IoU = 0.02\nFrame 89: IoU = 0.02\nFrame 90: IoU = 0.02\nFrame 91: IoU = 0.02\nFrame 92: IoU = 0.02\nFrame 93: IoU = 0.02\nFrame 94: IoU = 0.02\nFrame 95: IoU = 0.02\nFrame 96: IoU = 0.02\nFrame 97: IoU = 0.02\nFrame 98: IoU = 0.02\nFrame 99: IoU = 0.02\nFrame 100: IoU = 0.02\nFrame 101: IoU = 0.02\nFrame 102: IoU = 0.02\nFrame 103: IoU = 0.02\nFrame 104: IoU = 0.02\nFrame 105: IoU = 0.02\nFrame 106: IoU = 0.02\nFrame 107: IoU = 0.02\nFrame 108: IoU = 0.02\nFrame 109: IoU = 0.02\nFrame 110: IoU = 0.02\nFrame 111: IoU = 0.02\nFrame 112: IoU = 0.02\nFrame 113: IoU = 0.02\nFrame 114: IoU = 0.02\nFrame 115: IoU = 0.02\nFrame 116: IoU = 0.02\nFrame 117: IoU = 0.02\nFrame 118: IoU = 0.02\nFrame 119: IoU = 0.02\nFrame 120: IoU = 0.02\nFrame 121: IoU = 0.02\nFrame 122: IoU = 0.02\nFrame 123: IoU = 0.02\nFrame 124: IoU = 0.02\nFrame 125: IoU = 0.02\nFrame 126: IoU = 0.02\nFrame 127: IoU = 0.02\nFrame 128: IoU = 0.02\nFrame 129: IoU = 0.02\nFrame 130: IoU = 0.02\nFrame 131: IoU = 0.02\nFrame 132: IoU = 0.02\nFrame 133: IoU = 0.02\nFrame 134: IoU = 0.02\nFrame 135: IoU = 0.02\nFrame 136: IoU = 0.02\nFrame 137: IoU = 0.02\nFrame 138: IoU = 0.02\nFrame 139: IoU = 0.02\nFrame 140: IoU = 0.02\nFrame 141: IoU = 0.02\nFrame 142: IoU = 0.02\nFrame 143: IoU = 0.02\nFrame 144: IoU = 0.02\nFrame 145: IoU = 0.02\nFrame 146: IoU = 0.02\nFrame 147: IoU = 0.02\nFrame 148: IoU = 0.02\nFrame 149: IoU = 0.02\nFrame 150: IoU = 0.02\nFrame 151: IoU = 0.02\nFrame 152: IoU = 0.02\nFrame 153: IoU = 0.02\nFrame 154: IoU = 0.02\nFrame 155: IoU = 0.02\nFrame 156: IoU = 0.02\nFrame 157: IoU = 0.02\nFrame 158: IoU = 0.02\nFrame 159: IoU = 0.02\nFrame 160: IoU = 0.02\nFrame 161: IoU = 0.02\nFrame 162: IoU = 0.02\nFrame 163: IoU = 0.02\nFrame 164: IoU = 0.02\nFrame 165: IoU = 0.02\nFrame 166: IoU = 0.02\nFrame 167: IoU = 0.02\nFrame 168: IoU = 0.02\nFrame 169: IoU = 0.02\nFrame 170: IoU = 0.02\nFrame 171: IoU = 0.02\nFrame 172: IoU = 0.02\nFrame 173: IoU = 0.02\nFrame 174: IoU = 0.02\nFrame 175: IoU = 0.02\nFrame 176: IoU = 0.02\nFrame 177: IoU = 0.02\nFrame 178: IoU = 0.02\nFrame 179: IoU = 0.02\nFrame 180: IoU = 0.02\nFrame 181: IoU = 0.02\nFrame 182: IoU = 0.02\nFrame 183: IoU = 0.02\nFrame 184: IoU = 0.02\nFrame 185: IoU = 0.02\nFrame 186: IoU = 0.01\nFrame 187: IoU = 0.02\nFrame 188: IoU = 0.02\nFrame 189: IoU = 0.02\nFrame 190: IoU = 0.02\nFrame 191: IoU = 0.02\nFrame 192: IoU = 0.01\nFrame 193: IoU = 0.01\nFrame 194: IoU = 0.02\nFrame 195: IoU = 0.01\nFrame 196: IoU = 0.01\nFrame 197: IoU = 0.01\nFrame 198: IoU = 0.01\nFrame 199: IoU = 0.01\nFrame 200: IoU = 0.01\nFrame 201: IoU = 0.01\nFrame 202: IoU = 0.01\nFrame 203: IoU = 0.02\nFrame 204: IoU = 0.02\nFrame 205: IoU = 0.02\nFrame 206: IoU = 0.03\nFrame 207: IoU = 0.03\nFrame 208: IoU = 0.03\nFrame 209: IoU = 0.02\nFrame 210: IoU = 0.02\nFrame 211: IoU = 0.02\nFrame 212: IoU = 0.02\nFrame 213: IoU = 0.02\nFrame 214: IoU = 0.01\nFrame 215: IoU = 0.01\nFrame 216: IoU = 0.01\nFrame 217: IoU = 0.02\nFrame 218: IoU = 0.02\nFrame 219: IoU = 0.01\nFrame 220: IoU = 0.02\nFrame 221: IoU = 0.02\nFrame 222: IoU = 0.02\nFrame 223: IoU = 0.02\nFrame 224: IoU = 0.01\nFrame 225: IoU = 0.01\nFrame 226: IoU = 0.01\nFrame 227: IoU = 0.01\nFrame 228: IoU = 0.01\nFrame 229: IoU = 0.01\nFrame 230: IoU = 0.01\nFrame 231: IoU = 0.02\nFrame 232: IoU = 0.02\nFrame 233: IoU = 0.02\nFrame 234: IoU = 0.02\nFrame 235: IoU = 0.02\nFrame 236: IoU = 0.01\nFrame 237: IoU = 0.01\nFrame 238: IoU = 0.01\nFrame 239: IoU = 0.01\nFrame 240: IoU = 0.01\nFrame 241: IoU = 0.02\nFrame 242: IoU = 0.01\nFrame 243: IoU = 0.01\nFrame 244: IoU = 0.02\nFrame 245: IoU = 0.02\nFrame 246: IoU = 0.02\nFrame 247: IoU = 0.02\nFrame 248: IoU = 0.02\nFrame 249: IoU = 0.02\nFrame 250: IoU = 0.02\nFrame 251: IoU = 0.01\nFrame 252: IoU = 0.01\nFrame 253: IoU = 0.01\nFrame 254: IoU = 0.01\nFrame 255: IoU = 0.01\nFrame 256: IoU = 0.01\nFrame 257: IoU = 0.01\nFrame 258: IoU = 0.02\nFrame 259: IoU = 0.02\nFrame 260: IoU = 0.01\nFrame 261: IoU = 0.01\nFrame 262: IoU = 0.01\nFrame 263: IoU = 0.01\nFrame 264: IoU = 0.01\nFrame 265: IoU = 0.01\nFrame 266: IoU = 0.01\nFrame 267: IoU = 0.01\nFrame 268: IoU = 0.01\nFrame 269: IoU = 0.01\nFrame 270: IoU = 0.01\nFrame 271: IoU = 0.01\nFrame 272: IoU = 0.01\nFrame 273: IoU = 0.02\nFrame 274: IoU = 0.01\nFrame 275: IoU = 0.01\nFrame 276: IoU = 0.01\nFrame 277: IoU = 0.01\nFrame 278: IoU = 0.01\nFrame 279: IoU = 0.01\nFrame 280: IoU = 0.01\nFrame 281: IoU = 0.01\nFrame 282: IoU = 0.01\nFrame 283: IoU = 0.01\nFrame 284: IoU = 0.02\nFrame 285: IoU = 0.01\nFrame 286: IoU = 0.01\nFrame 287: IoU = 0.01\nFrame 288: IoU = 0.01\nFrame 289: IoU = 0.01\nFrame 290: IoU = 0.02\nFrame 291: IoU = 0.01\nFrame 292: IoU = 0.01\nFrame 293: IoU = 0.02\nFrame 294: IoU = 0.01\nFrame 295: IoU = 0.02\nFrame 296: IoU = 0.02\nFrame 297: IoU = 0.02\nFrame 298: IoU = 0.02\nFrame 299: IoU = 0.02\nFrame 300: IoU = 0.02\nFrame 301: IoU = 0.02\nFrame 302: IoU = 0.02\nFrame 303: IoU = 0.02\nFrame 304: IoU = 0.02\nFrame 305: IoU = 0.02\nFrame 306: IoU = 0.02\nFrame 307: IoU = 0.02\nFrame 308: IoU = 0.02\nFrame 309: IoU = 0.02\nFrame 310: IoU = 0.02\nFrame 311: IoU = 0.02\nFrame 312: IoU = 0.02\nFrame 313: IoU = 0.02\nFrame 314: IoU = 0.02\nFrame 315: IoU = 0.02\nFrame 316: IoU = 0.02\nFrame 317: IoU = 0.02\nFrame 318: IoU = 0.02\nFrame 319: IoU = 0.02\nFrame 320: IoU = 0.02\nFrame 321: IoU = 0.02\nFrame 322: IoU = 0.02\nFrame 323: IoU = 0.02\nFrame 324: IoU = 0.02\nFrame 325: IoU = 0.01\nFrame 326: IoU = 0.02\nFrame 327: IoU = 0.02\nFrame 328: IoU = 0.02\nFrame 329: IoU = 0.02\nFrame 330: IoU = 0.02\nFrame 331: IoU = 0.02\nFrame 332: IoU = 0.02\nFrame 333: IoU = 0.02\nFrame 334: IoU = 0.01\nFrame 335: IoU = 0.02\nFrame 336: IoU = 0.02\nFrame 337: IoU = 0.01\nFrame 338: IoU = 0.01\nFrame 339: IoU = 0.01\nFrame 340: IoU = 0.01\nFrame 341: IoU = 0.01\nFrame 342: IoU = 0.01\nFrame 343: IoU = 0.01\nFrame 344: IoU = 0.01\nFrame 345: IoU = 0.02\nFrame 346: IoU = 0.01\nFrame 347: IoU = 0.01\nFrame 348: IoU = 0.01\nFrame 349: IoU = 0.01\nFrame 350: IoU = 0.01\nFrame 351: IoU = 0.02\nFrame 352: IoU = 0.02\nFrame 353: IoU = 0.02\nFrame 354: IoU = 0.02\nFrame 355: IoU = 0.02\nFrame 356: IoU = 0.02\nFrame 357: IoU = 0.02\nFrame 358: IoU = 0.02\nFrame 359: IoU = 0.02\nFrame 360: IoU = 0.02\nFrame 361: IoU = 0.01\nFrame 362: IoU = 0.01\nFrame 363: IoU = 0.01\nFrame 364: IoU = 0.01\nFrame 365: IoU = 0.01\nFrame 366: IoU = 0.01\nFrame 367: IoU = 0.02\nFrame 368: IoU = 0.01\nFrame 369: IoU = 0.01\nFrame 370: IoU = 0.01\nFrame 371: IoU = 0.01\nFrame 372: IoU = 0.02\nFrame 373: IoU = 0.02\nFrame 374: IoU = 0.02\nFrame 375: IoU = 0.02\nFrame 376: IoU = 0.01\nFrame 377: IoU = 0.02\nFrame 378: IoU = 0.02\nFrame 379: IoU = 0.02\nFrame 380: IoU = 0.02\nFrame 381: IoU = 0.02\nFrame 382: IoU = 0.01\nFrame 383: IoU = 0.01\nFrame 384: IoU = 0.01\nFrame 385: IoU = 0.01\nFrame 386: IoU = 0.01\nFrame 387: IoU = 0.01\nFrame 388: IoU = 0.01\nFrame 389: IoU = 0.01\nFrame 390: IoU = 0.01\nFrame 391: IoU = 0.01\nFrame 392: IoU = 0.01\nFrame 393: IoU = 0.01\nFrame 394: IoU = 0.01\nFrame 395: IoU = 0.01\nFrame 396: IoU = 0.01\nFrame 397: IoU = 0.01\nFrame 398: IoU = 0.01\nFrame 399: IoU = 0.01\nFrame 400: IoU = 0.01\nFrame 401: IoU = 0.01\nFrame 402: IoU = 0.01\nFrame 403: IoU = 0.01\nFrame 404: IoU = 0.01\nFrame 405: IoU = 0.01\nFrame 406: IoU = 0.01\nFrame 407: IoU = 0.01\nFrame 408: IoU = 0.01\nFrame 409: IoU = 0.01\nFrame 410: IoU = 0.01\nFrame 411: IoU = 0.01\nFrame 412: IoU = 0.01\nFrame 413: IoU = 0.01\nFrame 414: IoU = 0.01\nFrame 415: IoU = 0.01\nFrame 416: IoU = 0.01\nFrame 417: IoU = 0.01\nFrame 418: IoU = 0.01\nFrame 419: IoU = 0.01\nFrame 420: IoU = 0.01\nFrame 421: IoU = 0.01\nFrame 422: IoU = 0.01\nFrame 423: IoU = 0.01\nFrame 424: IoU = 0.01\nFrame 425: IoU = 0.01\nFrame 426: IoU = 0.01\nFrame 427: IoU = 0.01\nFrame 428: IoU = 0.02\nFrame 429: IoU = 0.02\n"
        }
      ],
      "execution_count": 4,
      "metadata": {},
      "id": "4f6e1ef9-a45b-488a-b77e-b6152025f4ff"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "frame_ids, scores = zip(*iou_scores)\n",
        "\n",
        "plt.plot(frame_ids, scores, marker='o', linestyle='--', color='b')\n",
        "plt.title(\"IoU Scores Comparison\")\n",
        "plt.xlabel(\"Frame No\")\n",
        "plt.ylabel(\"IoU Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 640x480 with 1 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "155b4991-e00a-4054-a4ab-2c5a98745003"
    },
    {
      "cell_type": "code",
      "source": [
        "mean_iou = sum(score for _, score in iou_scores) / len(iou_scores)\n",
        "print(f\"Mean IoU Score: {mean_iou:.2f}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mean IoU Score: 0.02\n"
        }
      ],
      "execution_count": 6,
      "metadata": {},
      "id": "1e5cdd23-681f-460c-81f1-cd9c55665f28"
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "success_rate = sum(1 for _, score in iou_scores if score > threshold) / len(iou_scores) * 100\n",
        "print(f\"Baar Yzdesi (IoU > {threshold}): {success_rate:.2f}%\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Baar Yzdesi (IoU > 0.5): 0.00%\n"
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "1e712489-c493-4b87-806d-53e8a5da2958"
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"iou_results.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Frame ID\", \"IoU Score\"])\n",
        "    writer.writerows(iou_scores)\n",
        "print(\"Sonular iou_results.csv file saved.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Sonular iou_results.csv file saved.\n"
        }
      ],
      "execution_count": 8,
      "metadata": {},
      "id": "64b3edac-16b5-45f2-8db9-da959d3964a5"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_id = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    if frame_id not in ground_truth:\n",
        "        continue\n",
        "\n",
        "\n",
        "    gt_box = ground_truth[frame_id]\n",
        "    \n",
        "\n",
        "    results = model(frame)\n",
        "    \n",
        "    max_iou = 0\n",
        "    best_box = None\n",
        "    \n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            label = model.names[int(box.cls[0])]\n",
        "            \n",
        "            if label == \"person\":\n",
        "                detected_box = (x1, y1, x2, y2)\n",
        "                current_iou = iou(gt_box, detected_box)\n",
        "                \n",
        "            \n",
        "                if current_iou > max_iou:\n",
        "                    max_iou = current_iou\n",
        "                    best_box = detected_box\n",
        "\n",
        "\n",
        "    cv2.rectangle(frame, (gt_box[0], gt_box[1]), (gt_box[2], gt_box[3]), (255, 0, 0), 2)\n",
        "    cv2.putText(frame, \"Ground Truth\", (gt_box[0], gt_box[1] - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    if best_box:\n",
        "        cv2.rectangle(frame, (best_box[0], best_box[1]), (best_box[2], best_box[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"YOLO {max_iou:.2f}\", (best_box[0], best_box[1] - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow(\"Prediction and Actual Comparison\", frame)\n",
        "\n",
        "    # kmak iin 'q' tuuna bas\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n0: 384x640 19 persons, 1 umbrella, 166.4ms\nSpeed: 4.0ms preprocess, 166.4ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 183.0ms\nSpeed: 22.6ms preprocess, 183.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 159.7ms\nSpeed: 5.7ms preprocess, 159.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 134.4ms\nSpeed: 5.8ms preprocess, 134.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 168.8ms\nSpeed: 5.2ms preprocess, 168.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 141.8ms\nSpeed: 5.1ms preprocess, 141.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 horses, 1 umbrella, 135.7ms\nSpeed: 5.8ms preprocess, 135.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 horse, 1 umbrella, 129.3ms\nSpeed: 4.0ms preprocess, 129.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 133.7ms\nSpeed: 4.0ms preprocess, 133.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 145.7ms\nSpeed: 4.8ms preprocess, 145.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 142.4ms\nSpeed: 5.6ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 176.6ms\nSpeed: 6.3ms preprocess, 176.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 169.6ms\nSpeed: 0.0ms preprocess, 169.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 151.0ms\nSpeed: 5.0ms preprocess, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 182.4ms\nSpeed: 6.0ms preprocess, 182.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 145.4ms\nSpeed: 5.9ms preprocess, 145.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 handbag, 175.3ms\nSpeed: 5.1ms preprocess, 175.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 162.2ms\nSpeed: 4.9ms preprocess, 162.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 157.0ms\nSpeed: 12.2ms preprocess, 157.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 153.4ms\nSpeed: 15.6ms preprocess, 153.4ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 149.8ms\nSpeed: 6.0ms preprocess, 149.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 handbags, 135.1ms\nSpeed: 5.6ms preprocess, 135.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 172.2ms\nSpeed: 13.0ms preprocess, 172.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 220.2ms\nSpeed: 7.2ms preprocess, 220.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 182.1ms\nSpeed: 0.0ms preprocess, 182.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 163.7ms\nSpeed: 5.6ms preprocess, 163.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 187.0ms\nSpeed: 18.8ms preprocess, 187.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 147.9ms\nSpeed: 7.2ms preprocess, 147.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 175.5ms\nSpeed: 5.0ms preprocess, 175.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 158.6ms\nSpeed: 5.0ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 163.2ms\nSpeed: 6.0ms preprocess, 163.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 176.7ms\nSpeed: 5.5ms preprocess, 176.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 handbag, 217.6ms\nSpeed: 6.0ms preprocess, 217.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 207.9ms\nSpeed: 8.4ms preprocess, 207.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 186.7ms\nSpeed: 5.3ms preprocess, 186.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 handbags, 189.5ms\nSpeed: 5.0ms preprocess, 189.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 194.0ms\nSpeed: 6.0ms preprocess, 194.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 218.1ms\nSpeed: 6.8ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 1 handbag, 202.9ms\nSpeed: 6.0ms preprocess, 202.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 205.8ms\nSpeed: 6.0ms preprocess, 205.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 287.3ms\nSpeed: 6.0ms preprocess, 287.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 196.1ms\nSpeed: 7.1ms preprocess, 196.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 200.0ms\nSpeed: 5.0ms preprocess, 200.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 192.7ms\nSpeed: 5.0ms preprocess, 192.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 195.2ms\nSpeed: 20.9ms preprocess, 195.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 182.7ms\nSpeed: 8.3ms preprocess, 182.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 201.5ms\nSpeed: 15.6ms preprocess, 201.5ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 191.1ms\nSpeed: 9.6ms preprocess, 191.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 208.6ms\nSpeed: 11.3ms preprocess, 208.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 198.8ms\nSpeed: 5.0ms preprocess, 198.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 197.6ms\nSpeed: 11.8ms preprocess, 197.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 211.4ms\nSpeed: 6.0ms preprocess, 211.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 199.8ms\nSpeed: 17.1ms preprocess, 199.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 209.8ms\nSpeed: 7.0ms preprocess, 209.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 200.8ms\nSpeed: 11.5ms preprocess, 200.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 190.7ms\nSpeed: 6.1ms preprocess, 190.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 181.6ms\nSpeed: 8.0ms preprocess, 181.6ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 196.0ms\nSpeed: 8.5ms preprocess, 196.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 206.6ms\nSpeed: 0.0ms preprocess, 206.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 210.8ms\nSpeed: 17.7ms preprocess, 210.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 192.3ms\nSpeed: 8.0ms preprocess, 192.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 181.2ms\nSpeed: 6.0ms preprocess, 181.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 171.2ms\nSpeed: 5.1ms preprocess, 171.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 173.9ms\nSpeed: 5.5ms preprocess, 173.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 184.1ms\nSpeed: 5.0ms preprocess, 184.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.7ms\nSpeed: 7.5ms preprocess, 156.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 166.8ms\nSpeed: 5.0ms preprocess, 166.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 183.9ms\nSpeed: 0.0ms preprocess, 183.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 182.9ms\nSpeed: 10.0ms preprocess, 182.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 157.0ms\nSpeed: 18.4ms preprocess, 157.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 178.4ms\nSpeed: 5.5ms preprocess, 178.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 195.2ms\nSpeed: 0.0ms preprocess, 195.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 167.1ms\nSpeed: 6.0ms preprocess, 167.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 180.7ms\nSpeed: 0.0ms preprocess, 180.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 154.9ms\nSpeed: 19.9ms preprocess, 154.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 163.6ms\nSpeed: 6.4ms preprocess, 163.6ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 177.7ms\nSpeed: 0.0ms preprocess, 177.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 163.6ms\nSpeed: 6.1ms preprocess, 163.6ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 187.6ms\nSpeed: 0.0ms preprocess, 187.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 165.0ms\nSpeed: 6.0ms preprocess, 165.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 1 clock, 182.5ms\nSpeed: 11.5ms preprocess, 182.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 161.8ms\nSpeed: 7.4ms preprocess, 161.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 154.3ms\nSpeed: 4.8ms preprocess, 154.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 181.4ms\nSpeed: 4.5ms preprocess, 181.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 163.7ms\nSpeed: 8.0ms preprocess, 163.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 159.5ms\nSpeed: 5.0ms preprocess, 159.5ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 241.8ms\nSpeed: 6.3ms preprocess, 241.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 189.3ms\nSpeed: 5.0ms preprocess, 189.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 234.2ms\nSpeed: 3.0ms preprocess, 234.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 193.4ms\nSpeed: 1.6ms preprocess, 193.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 149.3ms\nSpeed: 6.0ms preprocess, 149.3ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 195.5ms\nSpeed: 6.5ms preprocess, 195.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 147.3ms\nSpeed: 7.0ms preprocess, 147.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 144.6ms\nSpeed: 6.8ms preprocess, 144.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 188.4ms\nSpeed: 6.0ms preprocess, 188.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 167.1ms\nSpeed: 16.5ms preprocess, 167.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 handbags, 1 tv, 183.8ms\nSpeed: 0.0ms preprocess, 183.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 4 handbags, 2 tvs, 183.3ms\nSpeed: 0.0ms preprocess, 183.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 tv, 167.3ms\nSpeed: 5.0ms preprocess, 167.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 166.4ms\nSpeed: 0.0ms preprocess, 166.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 146.4ms\nSpeed: 4.6ms preprocess, 146.4ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 166.8ms\nSpeed: 0.0ms preprocess, 166.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 170.1ms\nSpeed: 9.2ms preprocess, 170.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 176.8ms\nSpeed: 6.0ms preprocess, 176.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 169.5ms\nSpeed: 0.0ms preprocess, 169.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 159.1ms\nSpeed: 5.0ms preprocess, 159.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 160.7ms\nSpeed: 8.4ms preprocess, 160.7ms inference, 19.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 190.0ms\nSpeed: 6.0ms preprocess, 190.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 2 tvs, 201.7ms\nSpeed: 4.0ms preprocess, 201.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 3 tvs, 182.2ms\nSpeed: 9.0ms preprocess, 182.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 191.8ms\nSpeed: 4.6ms preprocess, 191.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 172.1ms\nSpeed: 6.3ms preprocess, 172.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 1 handbag, 1 tv, 201.5ms\nSpeed: 5.9ms preprocess, 201.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 1 tv, 195.0ms\nSpeed: 7.0ms preprocess, 195.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 handbag, 1 tv, 196.1ms\nSpeed: 20.8ms preprocess, 196.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 2 tvs, 172.3ms\nSpeed: 7.0ms preprocess, 172.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 183.9ms\nSpeed: 6.0ms preprocess, 183.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 186.2ms\nSpeed: 6.1ms preprocess, 186.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 189.9ms\nSpeed: 4.6ms preprocess, 189.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 1 clock, 165.7ms\nSpeed: 5.0ms preprocess, 165.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 186.3ms\nSpeed: 7.1ms preprocess, 186.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 2 tvs, 182.3ms\nSpeed: 20.6ms preprocess, 182.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 283.5ms\nSpeed: 5.0ms preprocess, 283.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 148.7ms\nSpeed: 5.0ms preprocess, 148.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 179.4ms\nSpeed: 7.5ms preprocess, 179.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 233.7ms\nSpeed: 6.8ms preprocess, 233.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 2 tvs, 177.0ms\nSpeed: 7.5ms preprocess, 177.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 157.0ms\nSpeed: 8.3ms preprocess, 157.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 155.6ms\nSpeed: 6.0ms preprocess, 155.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 1 tv, 1 clock, 333.6ms\nSpeed: 7.3ms preprocess, 333.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 2 tvs, 222.5ms\nSpeed: 7.5ms preprocess, 222.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 171.6ms\nSpeed: 0.0ms preprocess, 171.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 165.8ms\nSpeed: 5.9ms preprocess, 165.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 175.2ms\nSpeed: 6.0ms preprocess, 175.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 212.4ms\nSpeed: 5.0ms preprocess, 212.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 253.8ms\nSpeed: 7.6ms preprocess, 253.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 140.2ms\nSpeed: 5.5ms preprocess, 140.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 146.6ms\nSpeed: 6.4ms preprocess, 146.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 151.5ms\nSpeed: 6.0ms preprocess, 151.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 backpack, 1 umbrella, 1 handbag, 149.7ms\nSpeed: 6.8ms preprocess, 149.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 147.9ms\nSpeed: 5.0ms preprocess, 147.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 141.1ms\nSpeed: 5.0ms preprocess, 141.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 2 handbags, 165.1ms\nSpeed: 5.0ms preprocess, 165.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 212.1ms\nSpeed: 8.1ms preprocess, 212.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 1 tv, 173.7ms\nSpeed: 5.6ms preprocess, 173.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 172.9ms\nSpeed: 6.4ms preprocess, 172.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 161.2ms\nSpeed: 5.0ms preprocess, 161.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 150.9ms\nSpeed: 6.0ms preprocess, 150.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 275.8ms\nSpeed: 4.7ms preprocess, 275.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 1 clock, 351.4ms\nSpeed: 8.0ms preprocess, 351.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 249.0ms\nSpeed: 6.0ms preprocess, 249.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 147.0ms\nSpeed: 7.1ms preprocess, 147.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 horse, 229.9ms\nSpeed: 6.4ms preprocess, 229.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 350.6ms\nSpeed: 11.7ms preprocess, 350.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 230.4ms\nSpeed: 3.7ms preprocess, 230.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 194.7ms\nSpeed: 8.5ms preprocess, 194.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 269.5ms\nSpeed: 6.1ms preprocess, 269.5ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 286.0ms\nSpeed: 10.3ms preprocess, 286.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 234.1ms\nSpeed: 6.7ms preprocess, 234.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 458.2ms\nSpeed: 6.7ms preprocess, 458.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 239.0ms\nSpeed: 5.0ms preprocess, 239.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 251.7ms\nSpeed: 0.0ms preprocess, 251.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 265.0ms\nSpeed: 0.0ms preprocess, 265.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 272.0ms\nSpeed: 6.0ms preprocess, 272.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 255.8ms\nSpeed: 7.0ms preprocess, 255.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 245.3ms\nSpeed: 3.9ms preprocess, 245.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 236.5ms\nSpeed: 6.0ms preprocess, 236.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 232.6ms\nSpeed: 5.5ms preprocess, 232.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 183.4ms\nSpeed: 4.7ms preprocess, 183.4ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 229.1ms\nSpeed: 12.7ms preprocess, 229.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 202.8ms\nSpeed: 0.0ms preprocess, 202.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 203.1ms\nSpeed: 10.2ms preprocess, 203.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 183.2ms\nSpeed: 6.9ms preprocess, 183.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 235.3ms\nSpeed: 8.7ms preprocess, 235.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 261.3ms\nSpeed: 6.0ms preprocess, 261.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 349.1ms\nSpeed: 12.3ms preprocess, 349.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 260.2ms\nSpeed: 2.5ms preprocess, 260.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 240.5ms\nSpeed: 6.0ms preprocess, 240.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 260.2ms\nSpeed: 2.1ms preprocess, 260.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 clock, 293.7ms\nSpeed: 6.0ms preprocess, 293.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 270.0ms\nSpeed: 0.0ms preprocess, 270.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 273.4ms\nSpeed: 10.3ms preprocess, 273.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 248.0ms\nSpeed: 0.0ms preprocess, 248.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 265.5ms\nSpeed: 0.0ms preprocess, 265.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 260.7ms\nSpeed: 0.0ms preprocess, 260.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 268.4ms\nSpeed: 5.0ms preprocess, 268.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 265.0ms\nSpeed: 0.0ms preprocess, 265.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 249.6ms\nSpeed: 5.0ms preprocess, 249.6ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 256.7ms\nSpeed: 5.0ms preprocess, 256.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 261.6ms\nSpeed: 7.5ms preprocess, 261.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 267.7ms\nSpeed: 7.4ms preprocess, 267.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 257.7ms\nSpeed: 7.0ms preprocess, 257.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 276.5ms\nSpeed: 4.0ms preprocess, 276.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 268.5ms\nSpeed: 4.3ms preprocess, 268.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 horse, 1 umbrella, 233.8ms\nSpeed: 5.9ms preprocess, 233.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 2 handbags, 213.7ms\nSpeed: 8.0ms preprocess, 213.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 222.3ms\nSpeed: 4.1ms preprocess, 222.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 202.6ms\nSpeed: 5.3ms preprocess, 202.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 167.0ms\nSpeed: 9.0ms preprocess, 167.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 168.6ms\nSpeed: 6.0ms preprocess, 168.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 131.7ms\nSpeed: 17.2ms preprocess, 131.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 2 tvs, 142.4ms\nSpeed: 6.5ms preprocess, 142.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 152.8ms\nSpeed: 5.2ms preprocess, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 137.0ms\nSpeed: 6.4ms preprocess, 137.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 143.9ms\nSpeed: 5.0ms preprocess, 143.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 154.2ms\nSpeed: 5.0ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 137.5ms\nSpeed: 5.7ms preprocess, 137.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 176.9ms\nSpeed: 5.2ms preprocess, 176.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 166.3ms\nSpeed: 6.9ms preprocess, 166.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 1 clock, 144.0ms\nSpeed: 6.0ms preprocess, 144.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 184.0ms\nSpeed: 6.9ms preprocess, 184.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 145.8ms\nSpeed: 5.0ms preprocess, 145.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 164.4ms\nSpeed: 6.2ms preprocess, 164.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 157.0ms\nSpeed: 6.5ms preprocess, 157.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 181.6ms\nSpeed: 11.5ms preprocess, 181.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 137.9ms\nSpeed: 5.9ms preprocess, 137.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 147.6ms\nSpeed: 6.0ms preprocess, 147.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 164.8ms\nSpeed: 7.7ms preprocess, 164.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 315.5ms\nSpeed: 7.0ms preprocess, 315.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 1 clock, 161.7ms\nSpeed: 6.0ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 144.7ms\nSpeed: 5.2ms preprocess, 144.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 170.3ms\nSpeed: 8.1ms preprocess, 170.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 198.7ms\nSpeed: 6.0ms preprocess, 198.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 182.0ms\nSpeed: 5.9ms preprocess, 182.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 210.5ms\nSpeed: 6.0ms preprocess, 210.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 379.5ms\nSpeed: 8.0ms preprocess, 379.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 153.7ms\nSpeed: 6.6ms preprocess, 153.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 166.1ms\nSpeed: 7.0ms preprocess, 166.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 151.3ms\nSpeed: 5.0ms preprocess, 151.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 151.7ms\nSpeed: 6.0ms preprocess, 151.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 193.5ms\nSpeed: 6.0ms preprocess, 193.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 284.9ms\nSpeed: 6.0ms preprocess, 284.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 474.5ms\nSpeed: 19.0ms preprocess, 474.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 265.0ms\nSpeed: 6.7ms preprocess, 265.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 294.3ms\nSpeed: 5.0ms preprocess, 294.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 223.1ms\nSpeed: 6.0ms preprocess, 223.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 242.9ms\nSpeed: 6.5ms preprocess, 242.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 270.0ms\nSpeed: 6.0ms preprocess, 270.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 284.3ms\nSpeed: 9.9ms preprocess, 284.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 313.5ms\nSpeed: 5.0ms preprocess, 313.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 tv, 274.1ms\nSpeed: 6.0ms preprocess, 274.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 284.0ms\nSpeed: 7.0ms preprocess, 284.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 274.9ms\nSpeed: 6.0ms preprocess, 274.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 305.6ms\nSpeed: 5.0ms preprocess, 305.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 271.1ms\nSpeed: 5.0ms preprocess, 271.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 290.5ms\nSpeed: 9.0ms preprocess, 290.5ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 260.7ms\nSpeed: 6.7ms preprocess, 260.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 261.3ms\nSpeed: 7.0ms preprocess, 261.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 290.7ms\nSpeed: 17.3ms preprocess, 290.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 264.2ms\nSpeed: 9.7ms preprocess, 264.2ms inference, 22.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 437.9ms\nSpeed: 21.4ms preprocess, 437.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 1240.0ms\nSpeed: 6.0ms preprocess, 1240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 301.1ms\nSpeed: 6.0ms preprocess, 301.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 266.0ms\nSpeed: 16.0ms preprocess, 266.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 304.4ms\nSpeed: 7.0ms preprocess, 304.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 264.9ms\nSpeed: 9.0ms preprocess, 264.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 304.4ms\nSpeed: 7.8ms preprocess, 304.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 278.1ms\nSpeed: 7.9ms preprocess, 278.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 405.2ms\nSpeed: 6.0ms preprocess, 405.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 522.3ms\nSpeed: 6.0ms preprocess, 522.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 258.1ms\nSpeed: 5.0ms preprocess, 258.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 271.2ms\nSpeed: 6.9ms preprocess, 271.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 315.0ms\nSpeed: 7.1ms preprocess, 315.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 278.1ms\nSpeed: 7.0ms preprocess, 278.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 311.2ms\nSpeed: 5.0ms preprocess, 311.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 motorcycle, 2 tvs, 285.4ms\nSpeed: 6.0ms preprocess, 285.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 269.5ms\nSpeed: 5.0ms preprocess, 269.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 299.6ms\nSpeed: 4.0ms preprocess, 299.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 298.9ms\nSpeed: 10.0ms preprocess, 298.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 257.5ms\nSpeed: 8.0ms preprocess, 257.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 296.8ms\nSpeed: 5.0ms preprocess, 296.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 2 tvs, 288.2ms\nSpeed: 13.4ms preprocess, 288.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 357.9ms\nSpeed: 4.0ms preprocess, 357.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 236.9ms\nSpeed: 8.0ms preprocess, 236.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 249.4ms\nSpeed: 5.8ms preprocess, 249.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 3 tvs, 267.6ms\nSpeed: 5.0ms preprocess, 267.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 258.0ms\nSpeed: 5.0ms preprocess, 258.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 310.3ms\nSpeed: 10.1ms preprocess, 310.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 244.6ms\nSpeed: 21.0ms preprocess, 244.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 260.1ms\nSpeed: 7.6ms preprocess, 260.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 268.9ms\nSpeed: 6.0ms preprocess, 268.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 317.7ms\nSpeed: 7.0ms preprocess, 317.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 3 tvs, 239.0ms\nSpeed: 5.2ms preprocess, 239.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 226.5ms\nSpeed: 23.2ms preprocess, 226.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 2 tvs, 342.4ms\nSpeed: 5.0ms preprocess, 342.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 3 tvs, 326.5ms\nSpeed: 16.0ms preprocess, 326.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 402.2ms\nSpeed: 7.8ms preprocess, 402.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 302.6ms\nSpeed: 8.0ms preprocess, 302.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 336.4ms\nSpeed: 6.0ms preprocess, 336.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 3 tvs, 336.5ms\nSpeed: 6.0ms preprocess, 336.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 3 tvs, 333.7ms\nSpeed: 6.0ms preprocess, 333.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 backpack, 1 handbag, 1 tv, 332.6ms\nSpeed: 5.0ms preprocess, 332.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 handbag, 1 tv, 322.1ms\nSpeed: 6.0ms preprocess, 322.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 backpacks, 1 handbag, 2 tvs, 338.4ms\nSpeed: 19.4ms preprocess, 338.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 290.8ms\nSpeed: 8.0ms preprocess, 290.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 2 tvs, 340.9ms\nSpeed: 15.0ms preprocess, 340.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 umbrella, 2 tvs, 1201.9ms\nSpeed: 7.0ms preprocess, 1201.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 handbag, 2 tvs, 322.1ms\nSpeed: 12.9ms preprocess, 322.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 1 handbag, 2 tvs, 338.9ms\nSpeed: 15.1ms preprocess, 338.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 341.2ms\nSpeed: 5.0ms preprocess, 341.2ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 tv, 447.5ms\nSpeed: 6.0ms preprocess, 447.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 backpack, 1 umbrella, 2 tvs, 356.2ms\nSpeed: 26.0ms preprocess, 356.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 tv, 332.0ms\nSpeed: 6.0ms preprocess, 332.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 2 tvs, 267.3ms\nSpeed: 6.0ms preprocess, 267.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 241.0ms\nSpeed: 5.0ms preprocess, 241.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 210.1ms\nSpeed: 5.0ms preprocess, 210.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 228.4ms\nSpeed: 6.5ms preprocess, 228.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 212.0ms\nSpeed: 6.7ms preprocess, 212.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 233.2ms\nSpeed: 5.0ms preprocess, 233.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 220.3ms\nSpeed: 6.0ms preprocess, 220.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 252.0ms\nSpeed: 5.0ms preprocess, 252.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 2 tvs, 225.0ms\nSpeed: 6.0ms preprocess, 225.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 248.6ms\nSpeed: 5.0ms preprocess, 248.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 254.6ms\nSpeed: 6.0ms preprocess, 254.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 1 tv, 226.1ms\nSpeed: 6.8ms preprocess, 226.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 tv, 204.9ms\nSpeed: 6.0ms preprocess, 204.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 246.0ms\nSpeed: 6.5ms preprocess, 246.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 235.4ms\nSpeed: 6.5ms preprocess, 235.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 270.6ms\nSpeed: 5.0ms preprocess, 270.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 264.8ms\nSpeed: 15.6ms preprocess, 264.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 235.2ms\nSpeed: 5.0ms preprocess, 235.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 backpack, 1 umbrella, 252.1ms\nSpeed: 5.0ms preprocess, 252.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 229.6ms\nSpeed: 6.0ms preprocess, 229.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 167.7ms\nSpeed: 0.0ms preprocess, 167.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 188.0ms\nSpeed: 5.0ms preprocess, 188.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 247.3ms\nSpeed: 7.5ms preprocess, 247.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 244.5ms\nSpeed: 6.2ms preprocess, 244.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 200.2ms\nSpeed: 4.0ms preprocess, 200.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 276.1ms\nSpeed: 0.0ms preprocess, 276.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 248.6ms\nSpeed: 6.0ms preprocess, 248.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 243.5ms\nSpeed: 5.8ms preprocess, 243.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 238.7ms\nSpeed: 5.9ms preprocess, 238.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 256.8ms\nSpeed: 6.8ms preprocess, 256.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 239.3ms\nSpeed: 7.0ms preprocess, 239.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 26 persons, 1 umbrella, 245.2ms\nSpeed: 4.6ms preprocess, 245.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 255.8ms\nSpeed: 5.0ms preprocess, 255.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 255.8ms\nSpeed: 5.0ms preprocess, 255.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 933.2ms\nSpeed: 9.0ms preprocess, 933.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 302.8ms\nSpeed: 5.6ms preprocess, 302.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 314.9ms\nSpeed: 23.0ms preprocess, 314.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 342.5ms\nSpeed: 15.2ms preprocess, 342.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 276.5ms\nSpeed: 8.6ms preprocess, 276.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 272.2ms\nSpeed: 5.0ms preprocess, 272.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 278.1ms\nSpeed: 6.9ms preprocess, 278.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 253.0ms\nSpeed: 5.0ms preprocess, 253.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 300.1ms\nSpeed: 8.4ms preprocess, 300.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 240.6ms\nSpeed: 5.0ms preprocess, 240.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 200.2ms\nSpeed: 5.6ms preprocess, 200.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 183.0ms\nSpeed: 4.6ms preprocess, 183.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 234.9ms\nSpeed: 6.0ms preprocess, 234.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 253.7ms\nSpeed: 6.0ms preprocess, 253.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
        }
      ],
      "execution_count": 9,
      "metadata": {},
      "id": "a89d943a-f79f-412a-a1f3-37d249e2a823"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "frame_ids = []\n",
        "iou_scores = []\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_id = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    if frame_id not in ground_truth:\n",
        "        continue\n",
        "\n",
        "    gt_box = ground_truth[frame_id]\n",
        "    results = model(frame)\n",
        "    \n",
        "    max_iou = 0\n",
        "    \n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
        "            label = model.names[int(box.cls[0])]\n",
        "            \n",
        "            if label == \"person\":\n",
        "                detected_box = (x1, y1, x2, y2)\n",
        "                current_iou = iou(gt_box, detected_box)\n",
        "                max_iou = max(max_iou, current_iou)\n",
        "    \n",
        "  \n",
        "    frame_ids.append(frame_id)\n",
        "    iou_scores.append(max_iou)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# IoU Grafiini iz\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(frame_ids, iou_scores, label=\"IoU Skoru\", color=\"b\", marker=\"o\")\n",
        "plt.xlabel(\"Frame No\")\n",
        "plt.ylabel(\"IoU Score\")\n",
        "plt.title(\"YOLO Estimation and Ground Truth IoU Values\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n0: 384x640 19 persons, 1 umbrella, 455.5ms\nSpeed: 8.4ms preprocess, 455.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 258.8ms\nSpeed: 5.3ms preprocess, 258.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 232.9ms\nSpeed: 5.6ms preprocess, 232.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 242.1ms\nSpeed: 8.0ms preprocess, 242.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 349.8ms\nSpeed: 6.0ms preprocess, 349.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 280.7ms\nSpeed: 8.0ms preprocess, 280.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 horses, 1 umbrella, 258.6ms\nSpeed: 4.0ms preprocess, 258.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 horse, 1 umbrella, 226.9ms\nSpeed: 6.5ms preprocess, 226.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 272.8ms\nSpeed: 7.1ms preprocess, 272.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 276.8ms\nSpeed: 6.1ms preprocess, 276.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 282.9ms\nSpeed: 5.1ms preprocess, 282.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 247.2ms\nSpeed: 5.5ms preprocess, 247.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 202.4ms\nSpeed: 5.2ms preprocess, 202.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 154.9ms\nSpeed: 7.2ms preprocess, 154.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 153.3ms\nSpeed: 5.0ms preprocess, 153.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 137.2ms\nSpeed: 7.8ms preprocess, 137.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 handbag, 177.6ms\nSpeed: 5.3ms preprocess, 177.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 175.7ms\nSpeed: 2.0ms preprocess, 175.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 170.8ms\nSpeed: 4.9ms preprocess, 170.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 180.4ms\nSpeed: 6.0ms preprocess, 180.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 204.6ms\nSpeed: 7.0ms preprocess, 204.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 handbags, 139.5ms\nSpeed: 5.8ms preprocess, 139.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 169.7ms\nSpeed: 6.5ms preprocess, 169.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 150.7ms\nSpeed: 5.5ms preprocess, 150.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 143.9ms\nSpeed: 5.1ms preprocess, 143.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 179.5ms\nSpeed: 6.5ms preprocess, 179.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 146.9ms\nSpeed: 5.0ms preprocess, 146.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 152.9ms\nSpeed: 7.2ms preprocess, 152.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 181.9ms\nSpeed: 0.0ms preprocess, 181.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 168.8ms\nSpeed: 5.5ms preprocess, 168.8ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 186.2ms\nSpeed: 11.3ms preprocess, 186.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 231.4ms\nSpeed: 1.8ms preprocess, 231.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 handbag, 215.4ms\nSpeed: 3.4ms preprocess, 215.4ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 234.6ms\nSpeed: 11.9ms preprocess, 234.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 239.1ms\nSpeed: 9.3ms preprocess, 239.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 handbags, 186.3ms\nSpeed: 2.4ms preprocess, 186.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 177.0ms\nSpeed: 5.0ms preprocess, 177.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 169.7ms\nSpeed: 6.6ms preprocess, 169.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 1 handbag, 166.7ms\nSpeed: 6.3ms preprocess, 166.7ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 173.2ms\nSpeed: 6.0ms preprocess, 173.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 164.2ms\nSpeed: 6.0ms preprocess, 164.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 177.2ms\nSpeed: 8.1ms preprocess, 177.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 156.1ms\nSpeed: 6.9ms preprocess, 156.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 181.0ms\nSpeed: 6.0ms preprocess, 181.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 158.1ms\nSpeed: 4.7ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 208.1ms\nSpeed: 6.6ms preprocess, 208.1ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 214.9ms\nSpeed: 7.9ms preprocess, 214.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 180.6ms\nSpeed: 10.0ms preprocess, 180.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 189.0ms\nSpeed: 5.4ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 209.4ms\nSpeed: 6.0ms preprocess, 209.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 200.7ms\nSpeed: 5.0ms preprocess, 200.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 221.8ms\nSpeed: 0.0ms preprocess, 221.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 309.3ms\nSpeed: 5.2ms preprocess, 309.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 278.4ms\nSpeed: 0.0ms preprocess, 278.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 202.3ms\nSpeed: 15.6ms preprocess, 202.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 207.3ms\nSpeed: 5.7ms preprocess, 207.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 272.7ms\nSpeed: 6.0ms preprocess, 272.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 254.9ms\nSpeed: 0.0ms preprocess, 254.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 233.4ms\nSpeed: 15.2ms preprocess, 233.4ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 228.1ms\nSpeed: 14.9ms preprocess, 228.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 206.2ms\nSpeed: 6.0ms preprocess, 206.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 176.1ms\nSpeed: 17.5ms preprocess, 176.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 179.3ms\nSpeed: 15.6ms preprocess, 179.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 149.2ms\nSpeed: 15.6ms preprocess, 149.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 214.9ms\nSpeed: 0.0ms preprocess, 214.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 1 clock, 155.6ms\nSpeed: 6.1ms preprocess, 155.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 187.3ms\nSpeed: 8.3ms preprocess, 187.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 157.3ms\nSpeed: 5.1ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 212.1ms\nSpeed: 8.3ms preprocess, 212.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 156.2ms\nSpeed: 5.1ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 199.9ms\nSpeed: 0.0ms preprocess, 199.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 276.6ms\nSpeed: 0.0ms preprocess, 276.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 237.0ms\nSpeed: 5.0ms preprocess, 237.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 253.9ms\nSpeed: 18.3ms preprocess, 253.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 311.7ms\nSpeed: 7.0ms preprocess, 311.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 handbags, 1 tv, 219.6ms\nSpeed: 0.0ms preprocess, 219.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 4 handbags, 2 tvs, 166.7ms\nSpeed: 19.0ms preprocess, 166.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 tv, 158.6ms\nSpeed: 5.7ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 244.7ms\nSpeed: 8.0ms preprocess, 244.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 224.1ms\nSpeed: 10.7ms preprocess, 224.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 202.3ms\nSpeed: 5.0ms preprocess, 202.3ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 199.5ms\nSpeed: 5.0ms preprocess, 199.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 handbag, 1 tv, 313.4ms\nSpeed: 5.0ms preprocess, 313.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 258.3ms\nSpeed: 6.0ms preprocess, 258.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 327.9ms\nSpeed: 5.0ms preprocess, 327.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 handbag, 1 tv, 219.9ms\nSpeed: 5.0ms preprocess, 219.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 217.5ms\nSpeed: 5.5ms preprocess, 217.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 handbag, 2 tvs, 214.3ms\nSpeed: 5.7ms preprocess, 214.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 3 tvs, 202.5ms\nSpeed: 10.1ms preprocess, 202.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 1 tv, 190.8ms\nSpeed: 4.5ms preprocess, 190.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 handbag, 1 tv, 208.3ms\nSpeed: 4.7ms preprocess, 208.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 1 handbag, 1 tv, 202.5ms\nSpeed: 6.4ms preprocess, 202.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 1 tv, 205.3ms\nSpeed: 12.4ms preprocess, 205.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 handbag, 1 tv, 220.5ms\nSpeed: 10.1ms preprocess, 220.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 backpack, 1 handbag, 2 tvs, 220.1ms\nSpeed: 6.0ms preprocess, 220.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 220.7ms\nSpeed: 0.4ms preprocess, 220.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 220.7ms\nSpeed: 6.3ms preprocess, 220.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 231.5ms\nSpeed: 8.0ms preprocess, 231.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 2 tvs, 1 clock, 217.4ms\nSpeed: 6.6ms preprocess, 217.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 234.3ms\nSpeed: 6.0ms preprocess, 234.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 2 tvs, 217.1ms\nSpeed: 6.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 229.2ms\nSpeed: 6.0ms preprocess, 229.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 backpack, 1 umbrella, 1 handbag, 1 tv, 174.0ms\nSpeed: 5.5ms preprocess, 174.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 246.7ms\nSpeed: 0.0ms preprocess, 246.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 185.7ms\nSpeed: 6.0ms preprocess, 185.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 2 tvs, 191.9ms\nSpeed: 6.3ms preprocess, 191.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 210.2ms\nSpeed: 0.0ms preprocess, 210.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 219.7ms\nSpeed: 6.5ms preprocess, 219.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 1 tv, 1 clock, 217.7ms\nSpeed: 6.0ms preprocess, 217.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 2 tvs, 220.3ms\nSpeed: 3.5ms preprocess, 220.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 223.9ms\nSpeed: 1.0ms preprocess, 223.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 221.3ms\nSpeed: 6.4ms preprocess, 221.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 11 persons, 1 umbrella, 1 handbag, 1 tv, 142.0ms\nSpeed: 7.0ms preprocess, 142.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 1 handbag, 1 tv, 147.8ms\nSpeed: 5.0ms preprocess, 147.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 1 handbag, 1 tv, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 167.6ms\nSpeed: 0.0ms preprocess, 167.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 backpack, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 2 handbags, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 2 handbags, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 152.9ms\nSpeed: 0.0ms preprocess, 152.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 163.6ms\nSpeed: 0.0ms preprocess, 163.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 handbag, 1 clock, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 horse, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 158.2ms\nSpeed: 0.0ms preprocess, 158.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 177.3ms\nSpeed: 0.0ms preprocess, 177.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 153.9ms\nSpeed: 0.0ms preprocess, 153.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 166.4ms\nSpeed: 0.0ms preprocess, 166.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 166.8ms\nSpeed: 5.0ms preprocess, 166.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 146.7ms\nSpeed: 5.0ms preprocess, 146.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 172.1ms\nSpeed: 15.6ms preprocess, 172.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 151.0ms\nSpeed: 6.0ms preprocess, 151.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 165.9ms\nSpeed: 15.6ms preprocess, 165.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 159.7ms\nSpeed: 5.0ms preprocess, 159.7ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 153.8ms\nSpeed: 6.0ms preprocess, 153.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 169.3ms\nSpeed: 5.6ms preprocess, 169.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 156.2ms\nSpeed: 1.5ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 154.7ms\nSpeed: 15.6ms preprocess, 154.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 159.6ms\nSpeed: 19.9ms preprocess, 159.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 178.2ms\nSpeed: 4.0ms preprocess, 178.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 clock, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 182.2ms\nSpeed: 15.6ms preprocess, 182.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 1 handbag, 161.7ms\nSpeed: 15.6ms preprocess, 161.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 1 handbag, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 1 tv, 188.1ms\nSpeed: 15.6ms preprocess, 188.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 194.4ms\nSpeed: 15.6ms preprocess, 194.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 201.7ms\nSpeed: 6.0ms preprocess, 201.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 233.2ms\nSpeed: 4.6ms preprocess, 233.2ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 horse, 1 umbrella, 212.6ms\nSpeed: 6.9ms preprocess, 212.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 2 handbags, 177.8ms\nSpeed: 5.0ms preprocess, 177.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 205.9ms\nSpeed: 0.0ms preprocess, 205.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 218.2ms\nSpeed: 5.5ms preprocess, 218.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 handbag, 2 tvs, 170.3ms\nSpeed: 5.0ms preprocess, 170.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 177.3ms\nSpeed: 0.0ms preprocess, 177.3ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 backpack, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 158.3ms\nSpeed: 9.0ms preprocess, 158.3ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 1 clock, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 tv, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 tv, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 tv, 155.4ms\nSpeed: 15.6ms preprocess, 155.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 150.7ms\nSpeed: 15.6ms preprocess, 150.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 1 clock, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 157.6ms\nSpeed: 0.0ms preprocess, 157.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 155.9ms\nSpeed: 0.0ms preprocess, 155.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 167.4ms\nSpeed: 0.0ms preprocess, 167.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 160.1ms\nSpeed: 15.6ms preprocess, 160.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 248.6ms\nSpeed: 6.3ms preprocess, 248.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 180.5ms\nSpeed: 15.6ms preprocess, 180.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 168.3ms\nSpeed: 5.0ms preprocess, 168.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 177.2ms\nSpeed: 0.0ms preprocess, 177.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 185.7ms\nSpeed: 0.0ms preprocess, 185.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 140.6ms\nSpeed: 7.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 2 tvs, 146.0ms\nSpeed: 0.0ms preprocess, 146.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 tv, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 138.4ms\nSpeed: 0.0ms preprocess, 138.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 148.1ms\nSpeed: 15.6ms preprocess, 148.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 156.9ms\nSpeed: 0.0ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 tv, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 156.3ms\nSpeed: 15.6ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 161.6ms\nSpeed: 15.6ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 160.6ms\nSpeed: 0.0ms preprocess, 160.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 174.5ms\nSpeed: 6.0ms preprocess, 174.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 2 tvs, 176.6ms\nSpeed: 5.0ms preprocess, 176.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 166.5ms\nSpeed: 7.0ms preprocess, 166.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 tv, 166.6ms\nSpeed: 7.9ms preprocess, 166.6ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 tv, 158.3ms\nSpeed: 5.0ms preprocess, 158.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 2 tvs, 239.6ms\nSpeed: 0.0ms preprocess, 239.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 162.9ms\nSpeed: 10.7ms preprocess, 162.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 169.9ms\nSpeed: 6.0ms preprocess, 169.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 209.6ms\nSpeed: 5.0ms preprocess, 209.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 172.2ms\nSpeed: 5.0ms preprocess, 172.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 151.5ms\nSpeed: 6.3ms preprocess, 151.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 motorcycle, 2 tvs, 228.3ms\nSpeed: 15.6ms preprocess, 228.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 2 tvs, 202.8ms\nSpeed: 5.0ms preprocess, 202.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 226.8ms\nSpeed: 6.0ms preprocess, 226.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 175.6ms\nSpeed: 6.0ms preprocess, 175.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 365.9ms\nSpeed: 0.0ms preprocess, 365.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 216.8ms\nSpeed: 8.1ms preprocess, 216.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 2 tvs, 213.0ms\nSpeed: 6.3ms preprocess, 213.0ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 tvs, 344.0ms\nSpeed: 10.3ms preprocess, 344.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 253.7ms\nSpeed: 15.6ms preprocess, 253.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 2 tvs, 227.3ms\nSpeed: 5.3ms preprocess, 227.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 3 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 2 tvs, 218.7ms\nSpeed: 15.6ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 215.5ms\nSpeed: 15.6ms preprocess, 215.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 234.4ms\nSpeed: 0.0ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 2 tvs, 239.0ms\nSpeed: 0.0ms preprocess, 239.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 241.3ms\nSpeed: 0.0ms preprocess, 241.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 3 tvs, 269.6ms\nSpeed: 0.0ms preprocess, 269.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 3 tvs, 238.8ms\nSpeed: 5.0ms preprocess, 238.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 222.8ms\nSpeed: 8.0ms preprocess, 222.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 2 tvs, 265.6ms\nSpeed: 0.0ms preprocess, 265.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 3 tvs, 265.6ms\nSpeed: 0.0ms preprocess, 265.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 3 tvs, 250.0ms\nSpeed: 0.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 226.6ms\nSpeed: 0.0ms preprocess, 226.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 2 tvs, 217.4ms\nSpeed: 0.0ms preprocess, 217.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 3 tvs, 234.4ms\nSpeed: 15.6ms preprocess, 234.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 3 tvs, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 backpack, 1 handbag, 1 tv, 187.2ms\nSpeed: 0.0ms preprocess, 187.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 handbag, 1 tv, 175.0ms\nSpeed: 2.5ms preprocess, 175.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 2 backpacks, 1 handbag, 2 tvs, 169.8ms\nSpeed: 4.8ms preprocess, 169.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 2 tvs, 195.4ms\nSpeed: 0.0ms preprocess, 195.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 2 tvs, 160.3ms\nSpeed: 5.0ms preprocess, 160.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 umbrella, 2 tvs, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 handbag, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 1 handbag, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 handbag, 2 tvs, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 25 persons, 1 backpack, 1 umbrella, 2 tvs, 152.0ms\nSpeed: 0.0ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 backpack, 1 umbrella, 1 tv, 130.4ms\nSpeed: 18.0ms preprocess, 130.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 2 tvs, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 157.9ms\nSpeed: 0.0ms preprocess, 157.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 2 tvs, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 2 tvs, 145.9ms\nSpeed: 0.0ms preprocess, 145.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 2 tvs, 157.9ms\nSpeed: 0.0ms preprocess, 157.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 1 tv, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 1 tv, 152.0ms\nSpeed: 15.6ms preprocess, 152.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 138.8ms\nSpeed: 0.0ms preprocess, 138.8ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 140.6ms\nSpeed: 0.0ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 backpack, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.9ms\nSpeed: 0.0ms preprocess, 156.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 164.1ms\nSpeed: 0.0ms preprocess, 164.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 179.2ms\nSpeed: 15.9ms preprocess, 179.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 239.4ms\nSpeed: 0.0ms preprocess, 239.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 189.2ms\nSpeed: 5.0ms preprocess, 189.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 176.5ms\nSpeed: 0.0ms preprocess, 176.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 140.6ms\nSpeed: 4.1ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 backpack, 1 umbrella, 183.2ms\nSpeed: 15.6ms preprocess, 183.2ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 176.4ms\nSpeed: 4.0ms preprocess, 176.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 26 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 281.2ms\nSpeed: 0.0ms preprocess, 281.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 24 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 23 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 296.9ms\nSpeed: 15.6ms preprocess, 296.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 22 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 187.5ms\nSpeed: 15.6ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 387.7ms\nSpeed: 31.2ms preprocess, 387.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 203.1ms\nSpeed: 3.1ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 197.0ms\nSpeed: 0.0ms preprocess, 197.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 220.1ms\nSpeed: 0.0ms preprocess, 220.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 21 persons, 1 umbrella, 200.1ms\nSpeed: 0.0ms preprocess, 200.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 213.8ms\nSpeed: 6.7ms preprocess, 213.8ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 197.2ms\nSpeed: 0.0ms preprocess, 197.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 219.3ms\nSpeed: 0.6ms preprocess, 219.3ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 242.6ms\nSpeed: 0.0ms preprocess, 242.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 192.5ms\nSpeed: 18.8ms preprocess, 192.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 223.0ms\nSpeed: 15.6ms preprocess, 223.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 247.9ms\nSpeed: 0.0ms preprocess, 247.9ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 203.1ms\nSpeed: 0.0ms preprocess, 203.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 250.0ms\nSpeed: 15.6ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 12 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 281.2ms\nSpeed: 0.0ms preprocess, 281.2ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 187.5ms\nSpeed: 15.6ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 187.5ms\nSpeed: 15.6ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 20 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 198.2ms\nSpeed: 15.6ms preprocess, 198.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 188.0ms\nSpeed: 7.3ms preprocess, 188.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 282.8ms\nSpeed: 0.0ms preprocess, 282.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 140.6ms\nSpeed: 15.6ms preprocess, 140.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 227.1ms\nSpeed: 0.0ms preprocess, 227.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 156.2ms\nSpeed: 0.0ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 171.9ms\nSpeed: 0.0ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 200.6ms\nSpeed: 12.7ms preprocess, 200.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 190.5ms\nSpeed: 5.1ms preprocess, 190.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 200.9ms\nSpeed: 7.9ms preprocess, 200.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 171.9ms\nSpeed: 15.6ms preprocess, 171.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 171.0ms\nSpeed: 5.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 298.9ms\nSpeed: 14.3ms preprocess, 298.9ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 250.0ms\nSpeed: 0.0ms preprocess, 250.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 230.6ms\nSpeed: 0.0ms preprocess, 230.6ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 369.3ms\nSpeed: 7.0ms preprocess, 369.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 14 persons, 1 umbrella, 212.3ms\nSpeed: 15.6ms preprocess, 212.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 13 persons, 1 umbrella, 239.2ms\nSpeed: 6.0ms preprocess, 239.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 188.5ms\nSpeed: 5.6ms preprocess, 188.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 190.5ms\nSpeed: 0.0ms preprocess, 190.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 151.7ms\nSpeed: 6.6ms preprocess, 151.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 166.8ms\nSpeed: 8.0ms preprocess, 166.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 173.0ms\nSpeed: 0.0ms preprocess, 173.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 156.2ms\nSpeed: 15.6ms preprocess, 156.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 180.7ms\nSpeed: 5.5ms preprocess, 180.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 154.0ms\nSpeed: 5.0ms preprocess, 154.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 178.6ms\nSpeed: 5.5ms preprocess, 178.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 210.3ms\nSpeed: 5.0ms preprocess, 210.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 223.4ms\nSpeed: 15.6ms preprocess, 223.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 204.2ms\nSpeed: 12.3ms preprocess, 204.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 216.5ms\nSpeed: 15.6ms preprocess, 216.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 245.7ms\nSpeed: 0.0ms preprocess, 245.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 269.7ms\nSpeed: 15.6ms preprocess, 269.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 354.9ms\nSpeed: 58.2ms preprocess, 354.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 202.2ms\nSpeed: 0.0ms preprocess, 202.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 208.9ms\nSpeed: 0.0ms preprocess, 208.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 165.6ms\nSpeed: 5.0ms preprocess, 165.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 171.4ms\nSpeed: 15.6ms preprocess, 171.4ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 18 persons, 1 umbrella, 187.5ms\nSpeed: 15.6ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 189.0ms\nSpeed: 0.0ms preprocess, 189.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 197.1ms\nSpeed: 0.0ms preprocess, 197.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 15 persons, 1 umbrella, 187.5ms\nSpeed: 0.0ms preprocess, 187.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 200.2ms\nSpeed: 15.6ms preprocess, 200.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 17 persons, 1 umbrella, 199.1ms\nSpeed: 6.5ms preprocess, 199.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 16 persons, 1 umbrella, 223.1ms\nSpeed: 0.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 1 umbrella, 188.9ms\nSpeed: 5.0ms preprocess, 188.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n\n0: 384x640 19 persons, 218.7ms\nSpeed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 1000x600 with 1 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {},
      "id": "9a27beb2-a678-4af4-8ff0-a4886ce71ce5"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "box1 = [10, 20, 30, 40]  \n",
        "box2 = [15, 25, 35, 45]  \n",
        "\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "    x1_max = max(box1[0], box2[0])\n",
        "    y1_max = max(box1[1], box2[1])\n",
        "    x2_min = min(box1[2], box2[2])\n",
        "    y2_min = min(box1[3], box2[3])\n",
        "\n",
        "    intersection_area = max(0, x2_min - x1_max) * max(0, y2_min - y1_max)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "    iou = intersection_area / union_area if union_area > 0 else 0\n",
        "    return iou\n",
        "\n",
        "\n",
        "iou_value = compute_iou(box1, box2)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.set_xlim(0, 50)\n",
        "ax.set_ylim(0, 50)\n",
        "\n",
        "\n",
        "rect1 = patches.Rectangle((box1[0], box1[1]), box1[2] - box1[0], box1[3] - box1[1], linewidth=2, edgecolor='blue', facecolor='none')\n",
        "# Krmz kutu (YOLO tahmini)\n",
        "rect2 = patches.Rectangle((box2[0], box2[1]), box2[2] - box2[0], box2[3] - box1[1], linewidth=2, edgecolor='red', facecolor='none')\n",
        "\n",
        "\n",
        "ax.add_patch(rect1)\n",
        "ax.add_patch(rect2)\n",
        "\n",
        "plt.text(5, 45, f\"IoU: {iou_value:.4f}\", fontsize=12, color='black')\n",
        "\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": "<Figure size 600x600 with 1 Axes>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {},
      "id": "99789f36-a8cb-400c-a163-71026fe25eb9"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "6a5064e2-ddc3-424b-9ece-f5587d2af5bb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}